{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Full_EyeGazeSharedTask_FeaturesBERT_21.ipynb","provenance":[{"file_id":"1QenUej-cqKCo7OF3j2-gbtv2Vs618TAu","timestamp":1613744101895}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"118893f418654d73abe1c1084eeeeaf7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0ee0d5e35da14b559a987f6bc6e1e430","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b9e1ca7c29cb4148a115aedbcc2eebca","IPY_MODEL_4b259e2a6db94b038b274a7b44f02ec4"]}},"0ee0d5e35da14b559a987f6bc6e1e430":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b9e1ca7c29cb4148a115aedbcc2eebca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_02a75e83fec84882acb0d1c544dc76b9","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":898823,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":898823,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f4fd3bf9f5d842a4aa54997a3330b310"}},"4b259e2a6db94b038b274a7b44f02ec4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_df71e3a508314870a895f8bcf2334ebb","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 899k/899k [00:01&lt;00:00, 782kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4dcd771b6428484f805c37d613ccfe98"}},"02a75e83fec84882acb0d1c544dc76b9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f4fd3bf9f5d842a4aa54997a3330b310":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"df71e3a508314870a895f8bcf2334ebb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"4dcd771b6428484f805c37d613ccfe98":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a36744b24fd44258aff442eb2935a4d8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d4fe0b9aa7d144c09731fa9ba06d0684","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_28a8e45b597f4afdbcb60144a05083ef","IPY_MODEL_cb3d3e1bee95423aa3fac7b34c1fe875"]}},"d4fe0b9aa7d144c09731fa9ba06d0684":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"28a8e45b597f4afdbcb60144a05083ef":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d417cebb223e4ff9a3137f7378981dee","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":456318,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":456318,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_cd51887d64f947d584c0427f16dd5d09"}},"cb3d3e1bee95423aa3fac7b34c1fe875":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2a853c7064b3432e95d103e0c0c5bdec","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 456k/456k [00:00&lt;00:00, 1.27MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_eec2fef02ad84679adfc52542bbb8225"}},"d417cebb223e4ff9a3137f7378981dee":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"cd51887d64f947d584c0427f16dd5d09":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2a853c7064b3432e95d103e0c0c5bdec":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"eec2fef02ad84679adfc52542bbb8225":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"869663f62eab4e96bb685faf9d8bb63c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_73c6b5a0b4734365849f0f8c7c8c10fa","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7efa2954af0a4163aebcfa89773a7339","IPY_MODEL_7ebd7fac3f1d4a2b9c5ed4dc1e77745f"]}},"73c6b5a0b4734365849f0f8c7c8c10fa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7efa2954af0a4163aebcfa89773a7339":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_32ad2d91b7b0493ba09ddfb14d1c3b2d","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":481,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":481,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4f93804867c24c89a3c67339f11a3bd8"}},"7ebd7fac3f1d4a2b9c5ed4dc1e77745f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_d5b6e7273af342c381443d9726a1e22d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 481/481 [00:00&lt;00:00, 1.89kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ae39f100ca924aeba2f8c9ac5e5ffe51"}},"32ad2d91b7b0493ba09ddfb14d1c3b2d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4f93804867c24c89a3c67339f11a3bd8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"d5b6e7273af342c381443d9726a1e22d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ae39f100ca924aeba2f8c9ac5e5ffe51":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8d6c2985b7db4b6bafe01f8b6d7c6444":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ce0323e69b3f4aa683b1ba096a4c6bb6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a81594126ceb492f8174745104d325f7","IPY_MODEL_be2a20f5da9f44769ff52cda90f7da74"]}},"ce0323e69b3f4aa683b1ba096a4c6bb6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a81594126ceb492f8174745104d325f7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_4ca43e360dda45b8a7a567dafe8084e8","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":501200538,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":501200538,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_3dba46ea8fce490bb251e1dc0881ac04"}},"be2a20f5da9f44769ff52cda90f7da74":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_b14a9bc091f447a18e478f0f3ed70eda","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 501M/501M [00:10&lt;00:00, 47.8MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e490344a00144d79af540dd490613fbd"}},"4ca43e360dda45b8a7a567dafe8084e8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"3dba46ea8fce490bb251e1dc0881ac04":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b14a9bc091f447a18e478f0f3ed70eda":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"e490344a00144d79af540dd490613fbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"80bHKBp1j9ae","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614412853551,"user_tz":-330,"elapsed":2217,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"53590419-1553-4f71-ac4f-5eb526556356"},"source":["!nvidia-smi"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Sat Feb 27 08:00:52 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   76C    P0    32W /  70W |      0MiB / 15109MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oyBe-0ddKQaE"},"source":["# EYE GAZE SHARED TASK"]},{"cell_type":"code","metadata":{"id":"e8yEHuC4J9S1","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1614428980774,"user_tz":-330,"elapsed":4646,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"7ddc2587-a102-4c74-f5f7-67cfdfd9acfb"},"source":["import numpy as np\n","import pandas as pd\n","import re\n","import string\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import torch\n","import torch.nn as nn\n","from sklearn.metrics import r2_score\n","import pickle\n","from pickle import dump\n","import re\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.preprocessing import StandardScaler\n","from nltk import WordNetLemmatizer\n","from torch.utils.data import DataLoader, Dataset\n","from sklearn.model_selection import train_test_split\n","from nltk.tokenize import word_tokenize, sent_tokenize \n","from sklearn.preprocessing import OneHotEncoder\n","\n","enc = OneHotEncoder(sparse = False)\n","Lemmatizer = WordNetLemmatizer()\n","std_scaler = StandardScaler()\n","vectorizer = TfidfVectorizer(stop_words=None)\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","device"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'cpu'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"6n9NW6cI_cPv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614428987922,"user_tz":-330,"elapsed":9380,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"7275c1b7-06be-4d3c-830c-30fea1276c83"},"source":["!pip install transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/54/5ca07ec9569d2f232f3166de5457b63943882f7950ddfcc887732fc7fb23/transformers-4.3.3-py3-none-any.whl (1.9MB)\n","\u001b[K     |████████████████████████████████| 1.9MB 8.7MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 38.3MB/s \n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/23/2ddc317b2121117bf34dd00f5b0de194158f2a44ee2bf5e47c7166878a97/tokenizers-0.10.1-cp37-cp37m-manylinux2010_x86_64.whl (3.2MB)\n","\u001b[K     |████████████████████████████████| 3.2MB 50.6MB/s \n","\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp37-none-any.whl size=893262 sha256=39ca1d2f9a6809e3f5f676245a2902511fc70bda2acb7be1e9d1a2ba1c305d16\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UOMNpLleKSkN","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614429004087,"user_tz":-330,"elapsed":22525,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"f09a732a-a68f-4226-9155-5ba27ffa5d38"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"v44rV3j7kGo1"},"source":["### IMPORT TRANSFORMERS"]},{"cell_type":"code","metadata":{"id":"rRegTTBNKO8V","colab":{"base_uri":"https://localhost:8080/","height":322,"referenced_widgets":["118893f418654d73abe1c1084eeeeaf7","0ee0d5e35da14b559a987f6bc6e1e430","b9e1ca7c29cb4148a115aedbcc2eebca","4b259e2a6db94b038b274a7b44f02ec4","02a75e83fec84882acb0d1c544dc76b9","f4fd3bf9f5d842a4aa54997a3330b310","df71e3a508314870a895f8bcf2334ebb","4dcd771b6428484f805c37d613ccfe98","a36744b24fd44258aff442eb2935a4d8","d4fe0b9aa7d144c09731fa9ba06d0684","28a8e45b597f4afdbcb60144a05083ef","cb3d3e1bee95423aa3fac7b34c1fe875","d417cebb223e4ff9a3137f7378981dee","cd51887d64f947d584c0427f16dd5d09","2a853c7064b3432e95d103e0c0c5bdec","eec2fef02ad84679adfc52542bbb8225","869663f62eab4e96bb685faf9d8bb63c","73c6b5a0b4734365849f0f8c7c8c10fa","7efa2954af0a4163aebcfa89773a7339","7ebd7fac3f1d4a2b9c5ed4dc1e77745f","32ad2d91b7b0493ba09ddfb14d1c3b2d","4f93804867c24c89a3c67339f11a3bd8","d5b6e7273af342c381443d9726a1e22d","ae39f100ca924aeba2f8c9ac5e5ffe51","8d6c2985b7db4b6bafe01f8b6d7c6444","ce0323e69b3f4aa683b1ba096a4c6bb6","a81594126ceb492f8174745104d325f7","be2a20f5da9f44769ff52cda90f7da74","4ca43e360dda45b8a7a567dafe8084e8","3dba46ea8fce490bb251e1dc0881ac04","b14a9bc091f447a18e478f0f3ed70eda","e490344a00144d79af540dd490613fbd"]},"executionInfo":{"status":"ok","timestamp":1614429225857,"user_tz":-330,"elapsed":18268,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"9bd9b471-05ba-4b13-f56d-5195b55f703c"},"source":["#@title\n","#from transformers import BertTokenizer, BertForTokenClassification, BertModel\n","#from transformers import AlbertTokenizer, AlbertModel\n","#from transformers import ElectraForTokenClassification, ElectraTokenizer\n","from transformers import RobertaForTokenClassification, RobertaTokenizer\n","\n","tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\", add_prefix_space = True)\n","base_model = RobertaForTokenClassification.from_pretrained(\"roberta-base\")\n","\n","#tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n","#base_model = BertForTokenClassification.from_pretrained(\"bert-base-uncased\")\n","#base_model = BertModel.from_pretrained(\"bert-base-uncased\")\n","\n","#tokenizer = ElectraTokenizer.from_pretrained(\"google/electra-small-discriminator\")\n","#base_model = ElectraForTokenClassification.from_pretrained(\"google/electra-small-discriminator\")"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"118893f418654d73abe1c1084eeeeaf7","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"a36744b24fd44258aff442eb2935a4d8","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"869663f62eab4e96bb685faf9d8bb63c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=481.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"8d6c2985b7db4b6bafe01f8b6d7c6444","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=501200538.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForTokenClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"rtPkvPN0kJPV"},"source":["### DOWNLOAD DATA"]},{"cell_type":"code","metadata":{"id":"kRxJ5AXBLUy5"},"source":["train_data_file_path = \"/content/drive/My Drive/CMCL Shared Task/preprocessed_dataset.csv\"\n","test_data_file_path = \"/content/drive/My Drive/CMCL Shared Task/preprocessed_test_dataset.csv\"\n","#train_data_file_path = \"/content/drive/My Drive/CMCL Shared Task/training_data.csv\"\n","#test_data_file_path = \"/content/drive/My Drive/CMCL Shared Task/test_data.csv\"\n","\n","#file_path = \"/content/drive/MyDrive/datasets/EyeGazeSharedTask/trial_data.csv\"\n","\n","train_data = pd.read_csv(train_data_file_path)\n","test_data = pd.read_csv(test_data_file_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tZYNfiti9c-D","colab":{"base_uri":"https://localhost:8080/","height":459},"executionInfo":{"status":"ok","timestamp":1614429151305,"user_tz":-330,"elapsed":2088,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"c3ff9309-1fdc-4b4d-af31-519690183fd2"},"source":["print(\"Train Data Shape = \", train_data.shape)\n","print(\"Test Data Shape = \", test_data.shape)\n","df = train_data.copy()\n","test_df = test_data.copy()\n","\n","train_data"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train Data Shape =  (15736, 24)\n","Test Data Shape =  (3554, 19)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence_id</th>\n","      <th>word_id</th>\n","      <th>word</th>\n","      <th>nFix</th>\n","      <th>FFD</th>\n","      <th>GPT</th>\n","      <th>TRT</th>\n","      <th>fixProp</th>\n","      <th>endword</th>\n","      <th>n_tokens</th>\n","      <th>cf_n_tokens</th>\n","      <th>n_chars</th>\n","      <th>n_char_lemmatized</th>\n","      <th>stopword</th>\n","      <th>number</th>\n","      <th>tags</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>tf_idf</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Carlucci</td>\n","      <td>1.410757</td>\n","      <td>1.020764</td>\n","      <td>1.093189</td>\n","      <td>1.382395</td>\n","      <td>1.038428</td>\n","      <td>-1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NNP</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.178778</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>was</td>\n","      <td>-0.224947</td>\n","      <td>0.241393</td>\n","      <td>0.071056</td>\n","      <td>-0.204384</td>\n","      <td>0.361232</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>unk</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.060409</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>deputy</td>\n","      <td>1.066398</td>\n","      <td>1.841063</td>\n","      <td>0.053680</td>\n","      <td>1.053315</td>\n","      <td>1.264160</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>JJ</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.178778</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>defense</td>\n","      <td>0.549860</td>\n","      <td>1.455642</td>\n","      <td>0.274461</td>\n","      <td>0.837481</td>\n","      <td>0.812696</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.310704</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>secretary</td>\n","      <td>0.291591</td>\n","      <td>0.664334</td>\n","      <td>0.466622</td>\n","      <td>0.103379</td>\n","      <td>0.812696</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.275261</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>15731</th>\n","      <td>799</td>\n","      <td>4</td>\n","      <td>and</td>\n","      <td>-0.382778</td>\n","      <td>0.095297</td>\n","      <td>-0.282289</td>\n","      <td>-0.412446</td>\n","      <td>0.198203</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>unk</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.118080</td>\n","    </tr>\n","    <tr>\n","      <th>15732</th>\n","      <td>799</td>\n","      <td>5</td>\n","      <td>patient</td>\n","      <td>0.918133</td>\n","      <td>1.433756</td>\n","      <td>0.341808</td>\n","      <td>0.852136</td>\n","      <td>1.264160</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>JJ</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.454322</td>\n","    </tr>\n","    <tr>\n","      <th>15733</th>\n","      <td>799</td>\n","      <td>6</td>\n","      <td>wife</td>\n","      <td>0.348984</td>\n","      <td>0.340117</td>\n","      <td>-0.191064</td>\n","      <td>0.373357</td>\n","      <td>0.411395</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.343320</td>\n","    </tr>\n","    <tr>\n","      <th>15734</th>\n","      <td>799</td>\n","      <td>7</td>\n","      <td>of</td>\n","      <td>-0.057551</td>\n","      <td>0.836201</td>\n","      <td>-0.998577</td>\n","      <td>0.221104</td>\n","      <td>0.411395</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>unk</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.123557</td>\n","    </tr>\n","    <tr>\n","      <th>15735</th>\n","      <td>799</td>\n","      <td>8</td>\n","      <td>Homer</td>\n","      <td>-1.358462</td>\n","      <td>-1.623278</td>\n","      <td>-0.223403</td>\n","      <td>-1.215864</td>\n","      <td>-1.933709</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NNP</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.419091</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>15736 rows × 24 columns</p>\n","</div>"],"text/plain":["       sentence_id  word_id       word      nFix  ...    4    5    6    tf_idf\n","0                0        0   Carlucci  1.410757  ...  1.0  0.0  0.0  0.178778\n","1                0        1        was -0.224947  ...  0.0  0.0  1.0  0.060409\n","2                0        2     deputy  1.066398  ...  0.0  0.0  0.0  0.178778\n","3                0        3    defense  0.549860  ...  0.0  0.0  0.0  0.310704\n","4                0        4  secretary  0.291591  ...  0.0  0.0  0.0  0.275261\n","...            ...      ...        ...       ...  ...  ...  ...  ...       ...\n","15731          799        4        and -0.382778  ...  0.0  0.0  1.0  0.118080\n","15732          799        5    patient  0.918133  ...  0.0  0.0  0.0  0.454322\n","15733          799        6       wife  0.348984  ...  0.0  0.0  0.0  0.343320\n","15734          799        7         of -0.057551  ...  0.0  0.0  1.0  0.123557\n","15735          799        8      Homer -1.358462  ...  1.0  0.0  0.0  0.419091\n","\n","[15736 rows x 24 columns]"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"mqCmxok8owOC","executionInfo":{"status":"ok","timestamp":1614429151761,"user_tz":-330,"elapsed":1101,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"5c482b06-8372-4f1a-c95f-de42260948c9"},"source":["test_data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence_id</th>\n","      <th>word_id</th>\n","      <th>word</th>\n","      <th>endword</th>\n","      <th>n_tokens</th>\n","      <th>cf_n_tokens</th>\n","      <th>n_chars</th>\n","      <th>n_char_lemmatized</th>\n","      <th>stopword</th>\n","      <th>number</th>\n","      <th>tags</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>tf_idf</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>800</td>\n","      <td>0</td>\n","      <td>It's</td>\n","      <td>-1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NNP</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>800</td>\n","      <td>1</td>\n","      <td>the</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>DT</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.108989</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>800</td>\n","      <td>2</td>\n","      <td>funniest</td>\n","      <td>-1</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>unk</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.519424</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>800</td>\n","      <td>3</td>\n","      <td>American</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>JJ</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.296898</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>800</td>\n","      <td>4</td>\n","      <td>comedy</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.356212</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3549</th>\n","      <td>990</td>\n","      <td>5</td>\n","      <td>pursued</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>unk</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.010000</td>\n","    </tr>\n","    <tr>\n","      <th>3550</th>\n","      <td>990</td>\n","      <td>6</td>\n","      <td>a</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>DT</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <th>3551</th>\n","      <td>990</td>\n","      <td>7</td>\n","      <td>career</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.398571</td>\n","    </tr>\n","    <tr>\n","      <th>3552</th>\n","      <td>990</td>\n","      <td>8</td>\n","      <td>in</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>unk</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.137170</td>\n","    </tr>\n","    <tr>\n","      <th>3553</th>\n","      <td>990</td>\n","      <td>9</td>\n","      <td>politics</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.437429</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3554 rows × 19 columns</p>\n","</div>"],"text/plain":["      sentence_id  word_id      word  endword  ...    4    5    6    tf_idf\n","0             800        0      It's       -1  ...  1.0  0.0  0.0  0.000000\n","1             800        1       the       -1  ...  0.0  0.0  0.0  0.108989\n","2             800        2  funniest       -1  ...  0.0  0.0  1.0  0.519424\n","3             800        3  American       -1  ...  0.0  0.0  0.0  0.296898\n","4             800        4    comedy       -1  ...  0.0  0.0  0.0  0.356212\n","...           ...      ...       ...      ...  ...  ...  ...  ...       ...\n","3549          990        5   pursued       -1  ...  0.0  0.0  1.0  0.010000\n","3550          990        6         a       -1  ...  0.0  0.0  0.0  0.800000\n","3551          990        7    career       -1  ...  0.0  0.0  0.0  0.398571\n","3552          990        8        in       -1  ...  0.0  0.0  1.0  0.137170\n","3553          990        9  politics        1  ...  0.0  0.0  0.0  0.437429\n","\n","[3554 rows x 19 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"V7uWHqgmL8vm"},"source":["df_data = pd.read_csv(\"/content/drive/My Drive/CMCL Shared Task/Sentences_maxlen.csv\")\n","sentences = list(df_data[\"sentences\"])\n","MAX_LEN = df_data[\"max_len\"][0]\n","\n","test_df_data = pd.read_csv(\"/content/drive/My Drive/CMCL Shared Task/Test_Sentences_maxlen.csv\")\n","test_sentences = list(test_df_data[\"sentences\"])\n","test_MAX_LEN = test_df_data[\"max_len\"][0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"id":"ivuZkpAr_QKj","executionInfo":{"status":"ok","timestamp":1614412919623,"user_tz":-330,"elapsed":12015,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"207b0862-9b06-4264-a94c-8ce17fa7aa39"},"source":["test_sentences[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"It's the funniest American comedy since Graffiti Bridge.\""]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"PbjD1vIq2zno"},"source":["\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","\n","### PREPROCESS DATA"]},{"cell_type":"markdown","metadata":{"id":"fYLOLvUm1jOD"},"source":["#### REMOVE EOS TOKEN"]},{"cell_type":"code","metadata":{"id":"J1P_bWCs2baB","cellView":"form"},"source":["#@title\n","# FUNCTION TO REMOVE THE <EOS> TOKEN IN THE DATASET\n","\n","def remove_eos(df, train = True):\n","  cnt = 1\n","  if not train:\n","    cnt = 801\n","  endword = []\n","  for i in range(df.shape[0]-1):\n","    if (df.loc[i+1, \"sentence_id\"] == cnt):\n","      df.loc[i, \"word\"] = df.loc[i, \"word\"][:-5]   # Remove <EOS> for the last word of each sentence.\n","      cnt += 1\n","      endword.append(1)\n","    else:\n","      endword.append(-1) \n","  s = df.loc[df.shape[0] - 1, \"word\"]              # Remove <EOS> for last element separately\n","  df.loc[df.shape[0] - 1, \"word\"] = s[:-6] \n","  endword.append(1)\n","  df[\"endword\"] = endword\n","  return df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mLdln9oV17xX"},"source":["### COUNT NO OF TOKENS FOR EACH WORD"]},{"cell_type":"code","metadata":{"id":"bAkImkRF2xAp","colab":{"base_uri":"https://localhost:8080/","height":424},"executionInfo":{"status":"ok","timestamp":1614412966405,"user_tz":-330,"elapsed":6147,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"9f330851-7206-426c-a80f-f7a689595a78"},"source":["#@title\n","# FUNCTION TO CALCULATE NO OF TOKENS CREATED BY TOKENIZER PER WORD\n","# ADDS THE DATA IN A NEW COLUMN\n","\n","def add_token_per_words(df):\n","  n_tokens_per_word = []\n","  cdf = 0\n","  cf_n_token_per_word = []\n","  for i, word in enumerate(df.word):\n","    n_tokens_per_word.append(len(tokenizer.encode(word)) - 2)\n","    if (i > 0) and (df.loc[i-1, \"sentence_id\"] != df.loc[i, \"sentence_id\"]):\n","      cdf = 0\n","    cdf += len(tokenizer.encode(word)) - 2\n","    cf_n_token_per_word.append(cdf)\n","  df[\"n_tokens\"] = n_tokens_per_word\n","  df[\"cf_n_tokens\"] = cf_n_token_per_word\n","  return df\n","\n","#add_token_per_words(df)\n","#add_token_per_words(test_df)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence_id</th>\n","      <th>word_id</th>\n","      <th>word</th>\n","      <th>endword</th>\n","      <th>n_tokens</th>\n","      <th>cf_n_tokens</th>\n","      <th>n_chars</th>\n","      <th>n_char_lemmatized</th>\n","      <th>stopword</th>\n","      <th>number</th>\n","      <th>tags</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>tf_idf</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>800</td>\n","      <td>0</td>\n","      <td>It's</td>\n","      <td>-1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NNP</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>800</td>\n","      <td>1</td>\n","      <td>the</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>DT</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.108989</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>800</td>\n","      <td>2</td>\n","      <td>funniest</td>\n","      <td>-1</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>unk</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.519424</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>800</td>\n","      <td>3</td>\n","      <td>American</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>JJ</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.296898</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>800</td>\n","      <td>4</td>\n","      <td>comedy</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.356212</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3549</th>\n","      <td>990</td>\n","      <td>5</td>\n","      <td>pursued</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>unk</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.010000</td>\n","    </tr>\n","    <tr>\n","      <th>3550</th>\n","      <td>990</td>\n","      <td>6</td>\n","      <td>a</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>DT</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <th>3551</th>\n","      <td>990</td>\n","      <td>7</td>\n","      <td>career</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.398571</td>\n","    </tr>\n","    <tr>\n","      <th>3552</th>\n","      <td>990</td>\n","      <td>8</td>\n","      <td>in</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>unk</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.137170</td>\n","    </tr>\n","    <tr>\n","      <th>3553</th>\n","      <td>990</td>\n","      <td>9</td>\n","      <td>politics</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.437429</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3554 rows × 19 columns</p>\n","</div>"],"text/plain":["      sentence_id  word_id      word  endword  ...    4    5    6    tf_idf\n","0             800        0      It's       -1  ...  1.0  0.0  0.0  0.000000\n","1             800        1       the       -1  ...  0.0  0.0  0.0  0.108989\n","2             800        2  funniest       -1  ...  0.0  0.0  1.0  0.519424\n","3             800        3  American       -1  ...  0.0  0.0  0.0  0.296898\n","4             800        4    comedy       -1  ...  0.0  0.0  0.0  0.356212\n","...           ...      ...       ...      ...  ...  ...  ...  ...       ...\n","3549          990        5   pursued       -1  ...  0.0  0.0  1.0  0.010000\n","3550          990        6         a       -1  ...  0.0  0.0  0.0  0.800000\n","3551          990        7    career       -1  ...  0.0  0.0  0.0  0.398571\n","3552          990        8        in       -1  ...  0.0  0.0  1.0  0.137170\n","3553          990        9  politics        1  ...  0.0  0.0  0.0  0.437429\n","\n","[3554 rows x 19 columns]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"W0qirQb-2EE7"},"source":["### NO OF CHARS FOR EACH WORD"]},{"cell_type":"code","metadata":{"id":"JQ4D7kRN1cOB","cellView":"form"},"source":["#@title\n","# FUNCTION TO CALCULATE THE NUMBER OF CHARACTERS PER WORD\n","# ADDS THE DATA IN A NEW COLUMN\n","\n","def char_per_word(df):\n","  n_chars = []\n","  for word in df.word:\n","    n_chars.append(len(str(word)))\n","  df[\"n_chars\"] = n_chars\n","  return df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FJnVAg8QccsI"},"source":["### NO OF CHARS OF WORD - LEMMATIZED WORD"]},{"cell_type":"code","metadata":{"id":"6nVwk1nab9nf","cellView":"form"},"source":["#@title\n","# FUNCTION TO CALCULATE THE DIFFERENCE BETWEEN NUMBER OF CHARACTERS IN WORD AND LEMMATIZED WORD\n","# ADDS AS A NEW COLUMN\n","\n","def char_per_lemmatized_word(df):\n","  n_chars = []\n","  for word in df.word:\n","    n_chars.append(len(str(word)) - len(Lemmatizer.lemmatize(word)))\n","  df[\"n_char_lemmatized\"] = n_chars\n","  return df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gNya6DDO2KlQ"},"source":["### STOP WORD OR NOT"]},{"cell_type":"code","metadata":{"id":"P9wvuFxh1fKX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614281115343,"user_tz":-330,"elapsed":1667,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"ca7b5a30-63b6-4b48-8b2e-7afd4d64699d"},"source":["#@title\n","import nltk\n","nltk.download(\"stopwords\")\n","nltk.download(\"wordnet\")\n","\n","stopwords = nltk.corpus.stopwords\n","stop_words = stopwords.words(\"english\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/wordnet.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gvOW7IN72NJy"},"source":["#@title\n","# FUNCTION TO ASSERT WHETHER A WORD IS STOPWORD  OR NOT\n","# ADDS THE DATA IN A NEW COLUMN\n","\n","def add_stopword_check(df):\n","  if_stopword = []\n","  for word in df.word:\n","    if word in stop_words:\n","      if_stopword.append(1)\n","    else:\n","      if_stopword.append(-1)\n","\n","  df[\"stopword\"] = if_stopword\n","  return df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bzMv3ir42Wl4"},"source":["### NUMBER OR NOT"]},{"cell_type":"code","metadata":{"id":"6knkuEi12RAb","cellView":"form"},"source":["#@title\n","# FUNCTION TO DEFINE WHETHER IT IS A NUMBER OR NOT\n","# ADDS THE DATA AS A NEW COLUMN\n","\n","def add_number_check(df):\n","  if_number = []\n","  for word in df.word:\n","    if_number.append(1 if word.isdigit() else -1)\n","\n","  df[\"number\"] = if_number\n","  return df"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2AGt92OXu81b"},"source":["### TF IDF CALCULATION"]},{"cell_type":"code","metadata":{"id":"b_v29e6ccqag"},"source":["#@title\n","# FUNCTION TO CALCULATE THE TFIDF OF THE TRAINING DATASET\n","# ADDS THE DATA IN A NEW COLUMN\n","# ALSO RETURNS A LIST OF THE SENTENCES\n","\n","bad_words = []\n","punc = string.punctuation\n","\n","def remove_punc(word):\n","  table = str.maketrans('', '', punc)\n","  return word.translate(table)\n","\n","def calc_tfidf(df, train=True):\n","  start_pos = 0\n","  if not train:\n","    start_pos = 800\n","  n = np.array(df[\"sentence_id\"])[-1]\n","  sentences = []\n","  tf_idfs = []\n","  MAX_LEN = 0\n","  for i in range(start_pos, n+1):   \n","    temp_df = df[df.sentence_id == i]\n","    sentence = (' ').join(np.array(temp_df.word))\n","    sentences.append(sentence)\n","    MAX_LEN = max(MAX_LEN, len(sentence.split()))\n","  if train:\n","    tf_idf = vectorizer.fit_transform(sentences)\n","  else:\n","    tf_idf = vectorizer.transform(sentences)\n","\n","  for i, word in enumerate(df.word):\n","    try:\n","      tf_idfs.append(tf_idf.toarray()[df[\"sentence_id\"][i]- start_pos][vectorizer.get_feature_names().index(remove_punc(word.lower()))])\n","    except:\n","      bad_words.append(word)\n","      if word in [\"a\", \"A\", \"I\"]:\n","        tf_idfs.append(0.8)\n","      else:\n","        tf_idfs.append(0.01)\n","  df[\"tf_idf\"] = tf_idfs\n","\n","  return sentences, df, bad_words, MAX_LEN"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uODThGOIrKDA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614281117397,"user_tz":-330,"elapsed":1635,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"79dc9f78-98d0-408e-93bb-84ce199e4261"},"source":["#@title\n","nltk.download('averaged_perceptron_tagger')\n","nltk.download('punkt')\n","\n","convert_dict = {\"NNS\":\"NN\",\n","                \"PRP\":\"DT\",\n","                \"NN\":\"NN\",\n","                \"NNP\":\"NNP\",\n","                \"DT\":\"DT\",\n","                \"VB\":\"VB\",\n","                \"JJ\":\"JJ\",\n","                \"CD\":\"CD\"}\n","\n","def pos_tag_func(df, train=True):\n","  tags = []\n","  word_tag_tuple = nltk.pos_tag(df[\"word\"])\n","  for word, tag in word_tag_tuple:\n","    if tag in convert_dict.keys():\n","      tags.append(convert_dict[tag]) \n","    else:\n","      tags.append(\"unk\")\n","  df[\"tags\"] = tags\n","  \n","  if train:\n","    tag_transform = pd.DataFrame(enc.fit_transform(np.array(df.tags).reshape(-1, 1)))\n","  else:\n","    tag_transform = pd.DataFrame(enc.transform(np.array(df.tags).reshape(-1, 1)))\n","  df = pd.concat((df, tag_transform), axis = 1)\n","  return df"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package averaged_perceptron_tagger to\n","[nltk_data]     /root/nltk_data...\n","[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"T8IEDwE_rv5i"},"source":["#@title\n","def use_transformed_GPT(df):\n","  df[\"GPT\"] = df[\"TRT\"] - df[\"GPT\"]\n","  return df"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zww9QlLhxHfw"},"source":["# FUNCTION TO PERFORM ALL PREPROCESSING STEPS\n","def preprocess(df, train = True):\n","  return calc_tfidf(pos_tag_func(add_number_check(add_stopword_check(char_per_lemmatized_word(char_per_word(add_token_per_words(remove_eos(df, train)))))), train), train)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"RDDMJ7J8jInt","executionInfo":{"status":"ok","timestamp":1614281340212,"user_tz":-330,"elapsed":221824,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"0b911041-62eb-4493-db3c-1691e3a4ea0c"},"source":["sentences, df, bad_words, MAX_LEN = preprocess(train_data)\n","test_sentences, test_df, test_bad_words, test_MAX_LEN = preprocess(test_data, False)\n","df1 = df.copy()\n","df1"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence_id</th>\n","      <th>word_id</th>\n","      <th>word</th>\n","      <th>nFix</th>\n","      <th>FFD</th>\n","      <th>GPT</th>\n","      <th>TRT</th>\n","      <th>fixProp</th>\n","      <th>endword</th>\n","      <th>n_tokens</th>\n","      <th>cf_n_tokens</th>\n","      <th>n_chars</th>\n","      <th>n_char_lemmatized</th>\n","      <th>stopword</th>\n","      <th>number</th>\n","      <th>tags</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>tf_idf</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>Carlucci</td>\n","      <td>28.397566</td>\n","      <td>4.642973</td>\n","      <td>6.190631</td>\n","      <td>10.343594</td>\n","      <td>94.117647</td>\n","      <td>-1</td>\n","      <td>2</td>\n","      <td>2</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NNP</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.178778</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>was</td>\n","      <td>12.981744</td>\n","      <td>3.534385</td>\n","      <td>5.263977</td>\n","      <td>4.565348</td>\n","      <td>76.470588</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>unk</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.060409</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>deputy</td>\n","      <td>25.152130</td>\n","      <td>5.809781</td>\n","      <td>9.926357</td>\n","      <td>9.145251</td>\n","      <td>100.000000</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>JJ</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.178778</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>defense</td>\n","      <td>20.283976</td>\n","      <td>5.261551</td>\n","      <td>8.092455</td>\n","      <td>8.359293</td>\n","      <td>88.235294</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.310704</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>secretary</td>\n","      <td>17.849899</td>\n","      <td>4.135982</td>\n","      <td>4.507129</td>\n","      <td>5.686066</td>\n","      <td>88.235294</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>6</td>\n","      <td>9</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.275261</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>15731</th>\n","      <td>799</td>\n","      <td>4</td>\n","      <td>and</td>\n","      <td>11.494253</td>\n","      <td>3.326575</td>\n","      <td>6.183489</td>\n","      <td>3.807691</td>\n","      <td>72.222222</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>7</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>unk</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.118080</td>\n","    </tr>\n","    <tr>\n","      <th>15732</th>\n","      <td>799</td>\n","      <td>5</td>\n","      <td>patient</td>\n","      <td>23.754789</td>\n","      <td>5.230420</td>\n","      <td>7.826157</td>\n","      <td>8.412660</td>\n","      <td>100.000000</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>JJ</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.454322</td>\n","    </tr>\n","    <tr>\n","      <th>15733</th>\n","      <td>799</td>\n","      <td>6</td>\n","      <td>wife</td>\n","      <td>18.390805</td>\n","      <td>3.674811</td>\n","      <td>8.611980</td>\n","      <td>6.669187</td>\n","      <td>77.777778</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.343320</td>\n","    </tr>\n","    <tr>\n","      <th>15734</th>\n","      <td>799</td>\n","      <td>7</td>\n","      <td>of</td>\n","      <td>14.559387</td>\n","      <td>4.380448</td>\n","      <td>11.890443</td>\n","      <td>6.114758</td>\n","      <td>77.777778</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>unk</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.123557</td>\n","    </tr>\n","    <tr>\n","      <th>15735</th>\n","      <td>799</td>\n","      <td>8</td>\n","      <td>Homer</td>\n","      <td>2.298851</td>\n","      <td>0.882046</td>\n","      <td>2.978338</td>\n","      <td>0.882046</td>\n","      <td>16.666667</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NNP</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.419091</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>15736 rows × 24 columns</p>\n","</div>"],"text/plain":["       sentence_id  word_id       word       nFix  ...    4    5    6    tf_idf\n","0                0        0   Carlucci  28.397566  ...  1.0  0.0  0.0  0.178778\n","1                0        1        was  12.981744  ...  0.0  0.0  1.0  0.060409\n","2                0        2     deputy  25.152130  ...  0.0  0.0  0.0  0.178778\n","3                0        3    defense  20.283976  ...  0.0  0.0  0.0  0.310704\n","4                0        4  secretary  17.849899  ...  0.0  0.0  0.0  0.275261\n","...            ...      ...        ...        ...  ...  ...  ...  ...       ...\n","15731          799        4        and  11.494253  ...  0.0  0.0  1.0  0.118080\n","15732          799        5    patient  23.754789  ...  0.0  0.0  0.0  0.454322\n","15733          799        6       wife  18.390805  ...  0.0  0.0  0.0  0.343320\n","15734          799        7         of  14.559387  ...  0.0  0.0  1.0  0.123557\n","15735          799        8      Homer   2.298851  ...  1.0  0.0  0.0  0.419091\n","\n","[15736 rows x 24 columns]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"lPxOelroJgrB","executionInfo":{"status":"ok","timestamp":1614281340215,"user_tz":-330,"elapsed":220646,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"5570b5b4-c1d1-4351-9d56-d64e4a43dccd"},"source":["test_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence_id</th>\n","      <th>word_id</th>\n","      <th>word</th>\n","      <th>endword</th>\n","      <th>n_tokens</th>\n","      <th>cf_n_tokens</th>\n","      <th>n_chars</th>\n","      <th>n_char_lemmatized</th>\n","      <th>stopword</th>\n","      <th>number</th>\n","      <th>tags</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>tf_idf</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>800</td>\n","      <td>0</td>\n","      <td>It's</td>\n","      <td>-1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NNP</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>800</td>\n","      <td>1</td>\n","      <td>the</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>DT</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.108989</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>800</td>\n","      <td>2</td>\n","      <td>funniest</td>\n","      <td>-1</td>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>unk</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.519424</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>800</td>\n","      <td>3</td>\n","      <td>American</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>JJ</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.296898</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>800</td>\n","      <td>4</td>\n","      <td>comedy</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.356212</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3549</th>\n","      <td>990</td>\n","      <td>5</td>\n","      <td>pursued</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>unk</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.010000</td>\n","    </tr>\n","    <tr>\n","      <th>3550</th>\n","      <td>990</td>\n","      <td>6</td>\n","      <td>a</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>DT</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <th>3551</th>\n","      <td>990</td>\n","      <td>7</td>\n","      <td>career</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.398571</td>\n","    </tr>\n","    <tr>\n","      <th>3552</th>\n","      <td>990</td>\n","      <td>8</td>\n","      <td>in</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>unk</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.137170</td>\n","    </tr>\n","    <tr>\n","      <th>3553</th>\n","      <td>990</td>\n","      <td>9</td>\n","      <td>politics</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>12</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.437429</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3554 rows × 19 columns</p>\n","</div>"],"text/plain":["      sentence_id  word_id      word  endword  ...    4    5    6    tf_idf\n","0             800        0      It's       -1  ...  1.0  0.0  0.0  0.000000\n","1             800        1       the       -1  ...  0.0  0.0  0.0  0.108989\n","2             800        2  funniest       -1  ...  0.0  0.0  1.0  0.519424\n","3             800        3  American       -1  ...  0.0  0.0  0.0  0.296898\n","4             800        4    comedy       -1  ...  0.0  0.0  0.0  0.356212\n","...           ...      ...       ...      ...  ...  ...  ...  ...       ...\n","3549          990        5   pursued       -1  ...  0.0  0.0  1.0  0.010000\n","3550          990        6         a       -1  ...  0.0  0.0  0.0  0.800000\n","3551          990        7    career       -1  ...  0.0  0.0  0.0  0.398571\n","3552          990        8        in       -1  ...  0.0  0.0  1.0  0.137170\n","3553          990        9  politics        1  ...  0.0  0.0  0.0  0.437429\n","\n","[3554 rows x 19 columns]"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"code","metadata":{"id":"kq9lKYwYoLkv"},"source":["# FUNCTION TO NORMALISE ALL THE TARGET VALUES\n","def standardize_target(df):\n","  df = use_transformed_GPT(df)\n","  keys = df.keys()[3:8]\n","  new_df = pd.DataFrame(std_scaler.fit_transform(df.iloc[:,3:8]), columns = keys)\n","  df.update(new_df)\n","  return "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gbj2L1oGknaI"},"source":["standardize_target(df)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mf4jwohyoDgK"},"source":["df.to_csv(\"/content/drive/My Drive/CMCL Shared Task/preprocessed_dataset.csv\", index = False)\n","test_df.to_csv(\"/content/drive/My Drive/CMCL Shared Task/preprocessed_test_dataset.csv\", index = False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UeVmwktr8g8p"},"source":["sent_len_dict = {'sentences':sentences,\n","                 \"max_len\":MAX_LEN}\n","test_sent_len_dict = {'sentences':test_sentences,\n","                 \"max_len\":test_MAX_LEN}\n","\n","pd.DataFrame(sent_len_dict).to_csv(\"/content/drive/My Drive/CMCL Shared Task/Sentences_maxlen.csv\")\n","pd.DataFrame(test_sent_len_dict).to_csv(\"/content/drive/My Drive/CMCL Shared Task/Test_Sentences_maxlen.csv\")\n","\n","dump(std_scaler, open(\"/content/drive/My Drive/CMCL Shared Task/StandardScaler.pkl\", \"wb\"))\n","dump(vectorizer, open(\"/content/drive/My Drive/CMCL Shared Task/TfIdfVectorizer.pkl\", \"wb\"))\n","dump(enc, open(\"/content/drive/My Drive/CMCL Shared Task/OneHotEncoder.pkl\", \"wb\"))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oa30U4UpLvS1"},"source":["### FORM TARGETS"]},{"cell_type":"code","metadata":{"id":"vX5dljgA_7C-"},"source":["# FUNCTION TO FORM TARGETS AND OTHER FEATURES IN SEPARATE DATA STRUCTURES\n","\n","def form_targets(sentences, df, MAX_LEN, train = True):\n","  start_pos = 800\n","  if train:\n","    start_pos = 0\n","  n = np.array(df[\"sentence_id\"])[-1] - start_pos\n","  targets = []\n","  tags = []\n","  cdfs = []\n","  features = {\"n_chars\" : [],\n","              \"stopword\" : [],\n","              \"number\" : [],\n","              \"endword\":[],\n","              \"n_char_lemmatized\" : [],\n","              \"tf_idf\" : [],\n","              }\n","\n","  for i in range(n+1):\n","    feature = {}\n","    actual_features = {}\n","    temp_df = df[df.sentence_id == (i+start_pos)]\n","    \n","    cdf = [0 for i in range(MAX_LEN - len(sentences[i].split()))]\n","    actual_cdf = list(np.array(temp_df.loc[:, \"cf_n_tokens\"]))\n","    actual_cdf += cdf\n","\n","    if train:\n","      target = [[0, 0, 0, 0, 0] for i in range(MAX_LEN - len(sentences[i].split()))]\n","      actual_targets = [list(x/10) for x in np.array(temp_df.iloc[:, 3:8])]\n","      actual_targets += target\n","\n","    for key in features.keys():\n","      feature[key] = [0 for j in range(MAX_LEN - len(sentences[i].split()))]\n","      actual_features[key] = list(np.array(temp_df.loc[:, key]))\n","      actual_features[key] += feature[key]\n","\n","    tag = [[0 for j in range(6)] for k in range(MAX_LEN - len(sentences[i].split()))]\n","    actual_tag = [list(x) for x in np.array(temp_df.iloc[:, -8:-2])]\n","    actual_tag += tag\n","\n","    for key in features.keys():\n","      features[key].append(actual_features[key]) \n","    if train:\n","      targets.append(actual_targets) \n","    tags.append(actual_tag)\n","    cdfs.append(actual_cdf)\n","\n","  return targets, features, tags, cdfs\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"D3hUxj4Kj3ER","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614429175378,"user_tz":-330,"elapsed":3038,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"d4bfe1f2-196e-4ea5-b136-ec27ee71cff8"},"source":["MAX_LEN = MAX_LEN + 3*10\n","targets, features, tags, cdfs = form_targets(sentences, df, MAX_LEN)\n","print(\"Target Shape = \", np.array(targets, dtype = \"object\").shape)\n","test_targets, test_features, test_tags, test_cdfs = form_targets(test_sentences, test_df, MAX_LEN, False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Target Shape =  (800, 95, 5)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tnRqDwHK2yOm","executionInfo":{"status":"ok","timestamp":1614429177017,"user_tz":-330,"elapsed":1038,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"bfd27f22-065d-41ae-8aae-af3ff2f70531"},"source":["targets[0][0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.1410756913276762,\n"," 0.10207635501468597,\n"," 0.1093189493962106,\n"," 0.13823948188898844,\n"," 0.10384279377878629]"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y3TCRQGvS_hX","executionInfo":{"status":"ok","timestamp":1614429177478,"user_tz":-330,"elapsed":1283,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"1e0a1f41-8c66-41ae-8ec8-385dd2bdb00d"},"source":["MAX_LEN"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["95"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"VaAhnikZiHdu","cellView":"form"},"source":["#@title\n","class EarlyStopping:\n","    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n","    def __init__(self, patience=20, verbose=False, delta=0, path='checkpoint.pt', trace_func=print):\n","        \"\"\"\n","        Args:\n","            patience (int): How long to wait after last time validation loss improved.\n","                            Default: 7\n","            verbose (bool): If True, prints a message for each validation loss improvement. \n","                            Default: False\n","            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n","                            Default: 0\n","            path (str): Path for the checkpoint to be saved to.\n","                            Default: 'checkpoint.pt'\n","            trace_func (function): trace print function.\n","                            Default: print            \n","        \"\"\"\n","        self.patience = patience\n","        self.verbose = verbose\n","        self.counter = 0\n","        self.best_score = None\n","        self.early_stop = False\n","        self.val_loss_min = np.Inf\n","        self.delta = delta\n","        self.path = path\n","        self.trace_func = trace_func\n","    def __call__(self, val_loss, model):\n","\n","        score = -val_loss\n","\n","        if self.best_score is None:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","        elif score < self.best_score + self.delta:\n","            self.counter += 1\n","            self.trace_func(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n","            if self.counter >= self.patience:\n","                self.early_stop = True\n","        else:\n","            self.best_score = score\n","            self.save_checkpoint(val_loss, model)\n","            self.counter = 0\n","\n","    def save_checkpoint(self, val_loss, model):\n","        '''Saves model when validation loss decrease.'''\n","        if self.verbose:\n","            self.trace_func(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n","        torch.save(model.state_dict(), self.path)\n","        self.val_loss_min = val_loss\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VMB7hgQSRyS0"},"source":["### FORMING CLASS OF DATA"]},{"cell_type":"code","metadata":{"id":"f1UeHlE-OD19"},"source":["# Class for the data\n","# Contains 4 keys -> Sentences, targets, input_ids(for BERT), attention_mask(for BERT) \n","\n","class EyeGaze_dataset(Dataset):\n","\n","  def __init__(self, sentences, targets = None, cdfs = None, features = None, tags = None, tokenizer = None, train = True):\n","    self.sentences = sentences               # List of Sentences\n","    self.targets = targets                   # List of Padded Targets\n","    self.tokenizer = tokenizer               # Tokenizer to be used (BERT)\n","    self.cdfs = cdfs                         # Cumulative Frequency Function\n","    self.features = features\n","    self.tags = tags\n","    self.train = train\n","    \n","  def __len__(self):\n","    return len(self.sentences)               # No of Examples = 100\n","\n","  def __getitem__(self, index):\n","    sentence = str(self.sentences[index])        # Get the review at the particular index\n","    if self.train:\n","      target = self.targets[index]                    # Get the target label at the particular index\n","    cdf = self.cdfs[index]\n","    feature = {}\n","    for key in features.keys():\n","      feature[key] = features[key][index]\n","    tag = tags[index]\n","    encoding = self.tokenizer.encode_plus(   # Encoder encoding the particular review\n","        sentence,\n","        return_attention_mask = True,\n","        padding = \"max_length\",\n","        max_length = MAX_LEN,\n","        return_tensors = \"pt\"\n","    )\n","    # The class simply returns a dictionary of the following\n","    if self.train:\n","      return_dict = {\"target\":torch.tensor(target, dtype = torch.float32),\n","                    \"input_ids\":encoding[\"input_ids\"].flatten(),\n","                    \"attention_mask\":encoding[\"attention_mask\"].flatten(),\n","                    \"cdf\": torch.tensor(cdf, dtype = torch.int16),\n","                    \"tag\":torch.tensor(tag, dtype = torch.float32)}\n","    else:\n","      return_dict = {\"input_ids\":encoding[\"input_ids\"].flatten(),\n","                    \"attention_mask\":encoding[\"attention_mask\"].flatten(),\n","                    \"cdf\": torch.tensor(cdf, dtype = torch.int16),\n","                    \"tag\":torch.tensor(tag, dtype = torch.float32)}\n","    for key in features.keys():\n","      return_dict[key] = torch.tensor(feature[key], dtype = torch.float32)\n","\n","    return return_dict"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O9UZXPJ7PnLf"},"source":["# Forms the DataLoaders with test_size = 0.2\n","# Each DataLoader has the Class dataset as their elements\n","def create_data_loader(sentences, targets, cdfs, features, tags, tokenizer, batch_size, train = True):\n","  data = EyeGaze_dataset(sentences, targets, cdfs, features, tags, tokenizer, train)\n","  \n","  if train:\n","    train, val = train_test_split(data, test_size = 0.2, shuffle = True)\n","    train_data_loader = DataLoader(train, batch_size = batch_size, shuffle = False)\n","    val_data_loader = DataLoader(val, batch_size = batch_size, shuffle = False)\n","    return train_data_loader, val_data_loader\n","  test_data_loader = DataLoader(data, batch_size = batch_size, shuffle = False)\n","  return test_data_loader\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mWN0Chw_mYvA"},"source":["BATCH_SIZE = 8\n","train_data_loader, val_data_loader = create_data_loader(sentences, targets, cdfs, features, tags, tokenizer, BATCH_SIZE)\n","test_data_loader = create_data_loader(test_sentences, None, test_cdfs, test_features, test_tags, tokenizer, BATCH_SIZE, False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"RWaObK0LqAHv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614429233225,"user_tz":-330,"elapsed":942,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"3730c7f1-bbcb-4055-d2f9-f7e095d1ff8b"},"source":["temp = next(iter(train_data_loader))\n","print(temp.keys())\n","keys = ['target', 'input_ids', 'attention_mask',  'n_chars', 'n_char_lemmatized', 'cdf', 'stopword', 'number', 'tf_idf', \"tag\"]\n","for key in keys:\n","  print(temp[key].size())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["dict_keys(['target', 'input_ids', 'attention_mask', 'cdf', 'tag', 'n_chars', 'stopword', 'number', 'endword', 'n_char_lemmatized', 'tf_idf'])\n","torch.Size([8, 95, 5])\n","torch.Size([8, 95])\n","torch.Size([8, 95])\n","torch.Size([8, 95])\n","torch.Size([8, 95])\n","torch.Size([8, 95])\n","torch.Size([8, 95])\n","torch.Size([8, 95])\n","torch.Size([8, 95])\n","torch.Size([8, 95, 6])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QNhXpY38VZ5X","executionInfo":{"status":"ok","timestamp":1614429239407,"user_tz":-330,"elapsed":934,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"4bd7de5b-d81f-45cd-f448-c5ce9e9b9883"},"source":["for d in test_data_loader:\n","  print(\"tags dims = \", d[\"tag\"].size())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["tags dims =  torch.Size([8, 95, 6])\n","tags dims =  torch.Size([8, 95, 6])\n","tags dims =  torch.Size([8, 95, 6])\n","tags dims =  torch.Size([8, 95, 6])\n","tags dims =  torch.Size([8, 95, 6])\n","tags dims =  torch.Size([8, 95, 6])\n","tags dims =  torch.Size([8, 95, 6])\n","tags dims =  torch.Size([8, 95, 6])\n","tags dims =  torch.Size([8, 95, 6])\n","tags dims =  torch.Size([8, 95, 6])\n","tags dims =  torch.Size([8, 95, 6])\n","tags dims =  torch.Size([8, 95, 6])\n","tags dims =  torch.Size([8, 95, 6])\n","tags dims =  torch.Size([8, 95, 6])\n","tags dims =  torch.Size([8, 95, 6])\n","tags dims =  torch.Size([8, 95, 6])\n","tags dims =  torch.Size([8, 95, 6])\n","tags dims =  torch.Size([8, 95, 6])\n","tags dims =  torch.Size([8, 95, 6])\n","tags dims =  torch.Size([8, 95, 6])\n","tags dims =  torch.Size([8, 95, 6])\n","tags dims =  torch.Size([8, 95, 6])\n","tags dims =  torch.Size([8, 95, 6])\n","tags dims =  torch.Size([7, 95, 6])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ylwrgqaaoxk5"},"source":["base_model.config.output_hidden_states = True"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lei1xxFPN2M5"},"source":["class LanguageHeadLayer(torch.nn.Module):\n","  def __init__(self):\n","    super(LanguageHeadLayer, self).__init__()\n","    self.mid = torch.nn.Linear(in_features = base_model.config.hidden_size, out_features = 128)\n","    self.out = torch.nn.Linear(in_features = 128, out_features = 256)\n","    self.act1 = torch.nn.ReLU()\n","    self.act2 = torch.nn.GELU()\n","    self.drop = torch.nn.Dropout(p = 0.3)\n","\n","  def forward(self, output):\n","    output = self.mid(output)\n","    output = self.act2(output)\n","    output = self.drop(output)\n","    output = self.out(output)\n","\n","    return output\n","    \n","class ExtraFeatureModel(torch.nn.Module):\n","  def __init__(self):\n","    super(ExtraFeatureModel, self).__init__()\n","    self.inp = torch.nn.Linear(in_features = 12, out_features = 256)\n","    self.transformerlayer = torch.nn.TransformerEncoderLayer(d_model = 256, nhead = 8, dim_feedforward = 256, dropout = 0.2, activation = \"relu\")\n","    self.transformer = torch.nn.TransformerEncoder(self.transformerlayer, num_layers = 2)\n","    self.act1 = torch.nn.GELU()\n","    self.act2 = torch.nn.ReLU()\n","\n","  def forward(self, features):\n","    output = self.inp(features)\n","    output = self.act1(output)\n","    output = self.transformerlayer(output)\n","    output = torch.squeeze(output, dim = 0)\n","\n","    return output"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SpCysM36L4ux"},"source":["class EyeGazeClassifier(torch.nn.Module):\n","  def __init__(self):\n","    super(EyeGazeClassifier, self).__init__()\n","    self.base_model = base_model\n","    self.languageheadlayer = LanguageHeadLayer()\n","    self.feature_model = ExtraFeatureModel()\n","    self.out = torch.nn.Linear(in_features = 256, out_features = 5)\n","\n","  def map_predictions(self, outputs, attention_masks, cdfs):\n","    for i in range(outputs.size()[0]):    \n","      output = outputs[i]\n","      attention_mask = attention_masks[i]\n","      cdf = cdfs[i]\n","\n","      attention_mask = torch.unsqueeze(attention_mask, dim = 1)\n","\n","      output = output*attention_mask\n","\n","      pred_tensor = torch.unsqueeze(torch.mean(output[1:cdf[0]+1], dim = 0), dim = 0)\n","\n","      for j in range(0, len(cdf)-1):\n","        if (cdf[j+1] != 0):\n","          y = torch.unsqueeze(torch.mean(output[cdf[j]+1:cdf[j+1]+1], dim = 0), dim = 0)\n","          pred_tensor = torch.cat((pred_tensor, y), dim = 0)\n","\n","      pred_pad = torch.tensor([[0 for a in range(base_model.config.hidden_size)] for k in range(MAX_LEN - pred_tensor.size()[0])], dtype = torch.float32).to(device)\n","      pred_tensor = torch.cat((pred_tensor, pred_pad), dim = 0)\n","      if i==0:\n","        pred_tensors = torch.unsqueeze(pred_tensor, dim = 0)\n","      else:\n","        pred_tensors = torch.cat((pred_tensors, torch.unsqueeze(pred_tensor, dim = 0)), dim = 0)\n","\n","    return pred_tensors\n","\n","  def forward(self, input_ids, attention_mask, cdf, extra_features):\n","    lang_output = self.base_model(input_ids = input_ids, attention_mask = attention_mask)\n","    lang_output = self.map_predictions(lang_output[\"hidden_states\"][-1], attention_mask, cdf)\n","    lang_output = self.languageheadlayer(lang_output)\n","    feature_output = self.feature_model(extra_features)\n","    output = (lang_output+feature_output)/2\n","    output = self.out(output)\n","    \n","    return output\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h4x2Zmsnyo1E"},"source":["del model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OpzbkkBuhQ6x"},"source":["model = EyeGazeClassifier()\n","model = model.to(device)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pshm7LzymikU"},"source":["### TRAINING"]},{"cell_type":"code","metadata":{"id":"kMivdfe8mhwj"},"source":["#@title\n","EPOCHS = 120\n","from transformers import AdamW, get_linear_schedule_with_warmup\n","\n","opt_params = [{\"params\": model.languageheadlayer.parameters()},\n","              {\"params\": model.feature_model.parameters()},\n","              {\"params\": model.out.parameters()}]\n","\n","partial_optimizer = AdamW(opt_params, lr=2e-7, betas = (0.92, 0.998), correct_bias=False)\n","total_optimizer = AdamW(model.parameters(), lr = 4e-6, betas = (0.91, 0.998), weight_decay = 0, correct_bias = False)\n","\n","total_steps = len(train_data_loader) * EPOCHS\n","\n","partial_scheduler = get_linear_schedule_with_warmup(\n","  partial_optimizer,\n","  num_warmup_steps=6,\n","  num_training_steps=total_steps\n",")\n","\n","total_scheduler = get_linear_schedule_with_warmup(\n","  total_optimizer,\n","  num_warmup_steps=3,\n","  num_training_steps=total_steps\n",")\n","\n","loss_fn = nn.L1Loss(reduction = \"none\").to(device)  # reduction = \"mean\" can be used"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vgQwPYEV0pO-","cellView":"form"},"source":["#@title\n","def target_initialise():\n","  targets = {}\n","  outputs = {}\n","\n","  targets[\"r20\"] = torch.tensor([], dtype = torch.float32)\n","  targets[\"r21\"] = torch.tensor([], dtype = torch.float32)\n","  targets[\"r22\"] = torch.tensor([], dtype = torch.float32)\n","  targets[\"r23\"] = torch.tensor([], dtype = torch.float32)\n","  targets[\"r24\"] = torch.tensor([], dtype = torch.float32)\n","\n","  outputs[\"pred_r20\"] = torch.tensor([], dtype = torch.float32)\n","  outputs[\"pred_r21\"] = torch.tensor([], dtype = torch.float32)\n","  outputs[\"pred_r22\"] = torch.tensor([], dtype = torch.float32)\n","  outputs[\"pred_r23\"] = torch.tensor([], dtype = torch.float32)\n","  outputs[\"pred_r24\"] = torch.tensor([], dtype = torch.float32)\n","  \n","  return targets, outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sJl4qA4NAziZ","cellView":"form"},"source":["#@title\n","def store_targets(targets, target):\n","  targets[\"r20\"] = torch.cat([targets[\"r20\"], target[0,:,0].detach().cpu()], dim = 0)\n","  targets[\"r21\"] = torch.cat([targets[\"r21\"], target[0,:,1].detach().cpu()], dim = 0)\n","  targets[\"r22\"] = torch.cat([targets[\"r22\"], target[0,:,2].detach().cpu()], dim = 0)\n","  targets[\"r23\"] = torch.cat([targets[\"r23\"], target[0,:,3].detach().cpu()], dim = 0)\n","  targets[\"r24\"] = torch.cat([targets[\"r24\"], target[0,:,4].detach().cpu()], dim = 0)\n","\n","  return targets  \n","\n","def store_outputs(outputs, output):\n","  outputs[\"pred_r20\"] = torch.cat([outputs[\"pred_r20\"], output[0,:,0].detach().cpu()], dim = 0)\n","  outputs[\"pred_r21\"] = torch.cat([outputs[\"pred_r21\"], output[0,:,1].detach().cpu()], dim = 0)\n","  outputs[\"pred_r22\"] = torch.cat([outputs[\"pred_r22\"], output[0,:,2].detach().cpu()], dim = 0)\n","  outputs[\"pred_r23\"] = torch.cat([outputs[\"pred_r23\"], output[0,:,3].detach().cpu()], dim = 0)\n","  outputs[\"pred_r24\"] = torch.cat([outputs[\"pred_r24\"], output[0,:,4].detach().cpu()], dim = 0)\n","  \n","  return outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hAgYweVamhtT"},"source":["#@title\n","def train_epoch(model, data_loader, loss_fn, optimizer, device, scheduler):\n","  model = model.train()\n","\n","  losses = []\n","  targets, outputs = target_initialise()  \n","  loss_mask = torch.tensor([1, 1, 3, 1, 1]).to(device)\n","  r2 = {}\n","  with torch.autograd.set_detect_anomaly(True):\n","    for d in data_loader:\n","      input_ids = d[\"input_ids\"].to(device)\n","      attention_mask = d[\"attention_mask\"].to(device)\n","      target = d[\"target\"].to(device)\n","      cdf = d[\"cdf\"].to(device)\n","      char_len = torch.unsqueeze(d[\"n_chars\"], dim = 2)\n","      char_len_lemmatized = torch.unsqueeze(d[\"n_char_lemmatized\"], dim = 2)\n","      if_stopword = torch.unsqueeze(d[\"stopword\"], dim = 2)\n","      if_num = torch.unsqueeze(d['number'], dim = 2)\n","      if_end = torch.unsqueeze(d[\"endword\"], dim = 2)\n","      tfidf = torch.unsqueeze(d[\"tf_idf\"], dim = 2)\n","      tag = d[\"tag\"]\n","\n","      targets = store_targets(targets, target)\n","      extra_feature = torch.cat((char_len, char_len_lemmatized, if_stopword, if_num, if_end, tfidf, tag), dim = 2).to(device)\n","\n","      output = model(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask,\n","        cdf = cdf,\n","        extra_features = extra_feature\n","        )\n","\n","      outputs = store_outputs(outputs, output)\n","      \n","      loss = loss_fn(output, target)\n","      #loss = loss*loss_mask\n","      loss = loss.mean()\n","      losses.append(loss.item())\n","\n","      loss.backward()\n","      nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","      optimizer.step()\n","      scheduler.step()\n","      optimizer.zero_grad()\n","    \n","    r2[\"nFix\"] = r2_score(targets[\"r20\"].numpy(), outputs[\"pred_r20\"].numpy())\n","    r2[\"FFD\"] = r2_score(targets[\"r21\"].numpy(), outputs[\"pred_r21\"].numpy())\n","    r2[\"GPT\"] = r2_score(targets[\"r22\"].numpy(), outputs[\"pred_r22\"].numpy())\n","    r2[\"TRT\"] = r2_score(targets[\"r23\"].numpy(), outputs[\"pred_r23\"].numpy())\n","    r2[\"fixProp\"] = r2_score(targets[\"r24\"].numpy(), outputs[\"pred_r24\"].numpy())\n","    \n","  return np.mean(losses), r2    # correct_predictions.double() / n_examples,"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uScvRCt2mhqV"},"source":["#@title\n","def eval_model(model, data_loader, loss_fn, device):\n","  model = model.eval()\n","\n","  losses = []\n","  outputs = []\n","  r2 = {}\n","  targets, outputs = target_initialise()  \n","  loss_mask = torch.tensor([1, 1, 3, 1, 1]).to(device)\n","\n","  with torch.no_grad():\n","    for d in data_loader:\n","      input_ids = d[\"input_ids\"].to(device)\n","      attention_mask = d[\"attention_mask\"].to(device)\n","      target = d[\"target\"].to(device)\n","      cdf = d[\"cdf\"].to(device)\n","      char_len = torch.unsqueeze(d[\"n_chars\"], dim = 2)\n","      char_len_lemmatized = torch.unsqueeze(d[\"n_char_lemmatized\"], dim = 2)\n","      if_stopword = torch.unsqueeze(d[\"stopword\"], dim = 2)\n","      if_num = torch.unsqueeze(d['number'], dim = 2)\n","      if_end = torch.unsqueeze(d[\"endword\"], dim = 2)\n","      tfidf = torch.unsqueeze(d[\"tf_idf\"], dim = 2)   \n","      tag = d[\"tag\"]\n","      targets = store_targets(targets, target)\n","      extra_feature = torch.cat((char_len, char_len_lemmatized, if_stopword, if_num, if_end, tfidf, tag), dim = 2).to(device)\n","      \n","      output = model(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask,\n","        cdf = cdf,\n","        extra_features = extra_feature\n","        )\n","      \n","      outputs = store_outputs(outputs, output)\n","    \n","      loss = loss_fn(output, target)\n","      #loss = loss*loss_mask\n","      loss = loss.mean()\n","      losses.append(loss.item())\n","\n","  r2[\"nFix\"] = r2_score(targets[\"r20\"].numpy(), outputs[\"pred_r20\"].numpy())\n","  r2[\"FFD\"] = r2_score(targets[\"r21\"].numpy(), outputs[\"pred_r21\"].numpy())\n","  r2[\"GPT\"] = r2_score(targets[\"r22\"].numpy(), outputs[\"pred_r22\"].numpy())\n","  r2[\"TRT\"] = r2_score(targets[\"r23\"].numpy(), outputs[\"pred_r23\"].numpy())\n","  r2[\"fixProp\"] = r2_score(targets[\"r24\"].numpy(), outputs[\"pred_r24\"].numpy())\n","  \n","  return np.mean(losses), r2    # correct_predictions.double() / n_examples,"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mVfG9HWvWHVr"},"source":["def predict_model(model, data_loader, device):\n","  model = model.eval()\n","  print(\"Calculating Predictions on Test Set...\\n\")\n","  outputs = []\n","  _, outputs = target_initialise()  \n","  final_outputs = []\n","\n","  with torch.no_grad():\n","    for batch, d in enumerate(data_loader):\n","      input_ids = d[\"input_ids\"].to(device)\n","      attention_mask = d[\"attention_mask\"].to(device)\n","      cdf = d[\"cdf\"].to(device)\n","      char_len = torch.unsqueeze(d[\"n_chars\"], dim = 2)\n","      char_len_lemmatized = torch.unsqueeze(d[\"n_char_lemmatized\"], dim = 2)\n","      if_stopword = torch.unsqueeze(d[\"stopword\"], dim = 2)\n","      if_num = torch.unsqueeze(d['number'], dim = 2)\n","      if_end = torch.unsqueeze(d[\"endword\"], dim = 2)\n","      tfidf = torch.unsqueeze(d[\"tf_idf\"], dim = 2)   \n","      tag = d[\"tag\"]\n","      extra_feature = torch.cat((char_len, char_len_lemmatized, if_stopword, if_num, if_end, tfidf, tag), dim = 2).to(device)\n","      \n","      output = model(\n","        input_ids=input_ids,\n","        attention_mask=attention_mask,\n","        cdf = cdf,\n","        extra_features = extra_feature\n","        )\n","      \n","      for i in range(output.size()[0]):\n","        seq_len = len(test_sentences[i+batch*BATCH_SIZE].split())\n","        final_outputs += output[i, : seq_len, : ].tolist()\n","\n","    \n","  return final_outputs"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JLDMQGO9t-60","cellView":"form"},"source":["#@title\n","def save(history, best):\n","  for key, value in history.items():\n","    best[key] = value[-1]\n","\n","  return best\n","\n","def update(history, train_loss, val_loss, train_r2, val_r2):\n","  \n","  history['train_loss'].append(train_loss)\n","  history['val_loss'].append(val_loss)\n","\n","  history[\"train_nFix\"].append(train_r2[\"nFix\"])\n","  history[\"train_FFD\"].append(train_r2[\"FFD\"])\n","  history[\"train_GPT\"].append(train_r2[\"GPT\"])\n","  history[\"train_TRT\"].append(train_r2[\"TRT\"])\n","  history[\"train_fixProp\"].append(train_r2[\"fixProp\"])\n","\n","  history[\"val_nFix\"].append(val_r2[\"nFix\"])\n","  history[\"val_FFD\"].append(val_r2[\"FFD\"])\n","  history[\"val_GPT\"].append(val_r2[\"GPT\"])\n","  history[\"val_TRT\"].append(val_r2[\"TRT\"])\n","  history[\"val_fixProp\"].append(val_r2[\"fixProp\"])\n","\n","  return history"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jEZelBKThQiU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614416077074,"user_tz":-330,"elapsed":1325002,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"a65bb96a-9492-4b12-a60e-3c1219c748cc"},"source":["from collections import defaultdict\n","\n","history = defaultdict(list)\n","tolerance = 0\n","best = {}\n","best = {\"val_loss\" : 10000}\n","early_stopping = EarlyStopping(patience = 8, verbose = True, delta = 0.0)\n","\n","optimizer = total_optimizer\n","scheduler = total_scheduler\n","\n","for epoch in range(EPOCHS):\n","\n","  print(f'Epoch {epoch + 1}/{EPOCHS}')\n","  print('-' * 120)\n","\n","  train_loss, train_r2 = train_epoch(model,\n","    train_data_loader,    \n","    loss_fn, \n","    optimizer, \n","    device, \n","    scheduler)\n","  \n","\n","  print(f'Train loss {train_loss} and Train R2 {train_r2}')\n","\n","  val_loss, val_r2 = eval_model(\n","    model,\n","    val_data_loader,\n","    loss_fn, \n","    device\n","  )\n","\n","  print(f'Val loss {val_loss} and Val R2 {val_r2}')\n","  print()\n","\n","  history = update(history, train_loss, val_loss, train_r2, val_r2)\n","  \n","  if val_loss < best[\"val_loss\"]:\n","    best = save(history, best)\n","  \n","  early_stopping(val_loss, model)\n","  if early_stopping.early_stop:\n","    print(\"Stopped Early at at Epoch \", epoch+1)\n","    break\n","  model.load_state_dict(torch.load('checkpoint.pt'))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/120\n","------------------------------------------------------------------------------------------------------------------------\n","Train loss 0.011920027318410575 and Train R2 {'nFix': 0.7482725097898737, 'FFD': 0.674243057975719, 'GPT': 0.4525215365934364, 'TRT': 0.721654196850976, 'fixProp': 0.708408238846816}\n","Val loss 0.00948275316040963 and Val R2 {'nFix': 0.6115276148060191, 'FFD': 0.5857541416386363, 'GPT': 0.538755986538273, 'TRT': 0.5858300962562104, 'fixProp': 0.6562605528411755}\n","\n","Validation loss decreased (inf --> 0.009483).  Saving model ...\n","Epoch 2/120\n","------------------------------------------------------------------------------------------------------------------------\n","Train loss 0.01183812228264287 and Train R2 {'nFix': 0.7500065576133234, 'FFD': 0.6605473320506932, 'GPT': 0.4540793777367871, 'TRT': 0.7254723658367616, 'fixProp': 0.7135502853485877}\n","Val loss 0.009512994368560613 and Val R2 {'nFix': 0.6050594655960669, 'FFD': 0.5817123420281343, 'GPT': 0.5418824650456611, 'TRT': 0.5648547233763195, 'fixProp': 0.6580898076456152}\n","\n","EarlyStopping counter: 1 out of 8\n","Epoch 3/120\n","------------------------------------------------------------------------------------------------------------------------\n","Train loss 0.011807932960800826 and Train R2 {'nFix': 0.7437356042067194, 'FFD': 0.6669140737226954, 'GPT': 0.44644997666041963, 'TRT': 0.7301262444641115, 'fixProp': 0.7120980352781314}\n","Val loss 0.0094948239158839 and Val R2 {'nFix': 0.6057932116577539, 'FFD': 0.5854643208130337, 'GPT': 0.5420667445728434, 'TRT': 0.5758748385918712, 'fixProp': 0.6515128917935105}\n","\n","EarlyStopping counter: 2 out of 8\n","Epoch 4/120\n","------------------------------------------------------------------------------------------------------------------------\n","Train loss 0.011790719209238886 and Train R2 {'nFix': 0.7535858695038482, 'FFD': 0.6651650770153127, 'GPT': 0.46130401412121325, 'TRT': 0.7343275378014487, 'fixProp': 0.7196492722536582}\n","Val loss 0.009548306069336831 and Val R2 {'nFix': 0.6017583350904209, 'FFD': 0.5758798907786178, 'GPT': 0.5406885517982416, 'TRT': 0.5599017501874362, 'fixProp': 0.6492173081685549}\n","\n","EarlyStopping counter: 3 out of 8\n","Epoch 5/120\n","------------------------------------------------------------------------------------------------------------------------\n","Train loss 0.01180664598941803 and Train R2 {'nFix': 0.7466672702234598, 'FFD': 0.6715278024639764, 'GPT': 0.4501829091799331, 'TRT': 0.7376952118697186, 'fixProp': 0.7149575750461133}\n","Val loss 0.009433312038891018 and Val R2 {'nFix': 0.6086522631215379, 'FFD': 0.5856014131293995, 'GPT': 0.5394848134843429, 'TRT': 0.5781349191798543, 'fixProp': 0.6577944116073263}\n","\n","Validation loss decreased (0.009483 --> 0.009433).  Saving model ...\n","Epoch 6/120\n","------------------------------------------------------------------------------------------------------------------------\n","Train loss 0.011682235135231167 and Train R2 {'nFix': 0.7600579621943512, 'FFD': 0.6614832357037636, 'GPT': 0.44994582909081926, 'TRT': 0.7428807097300182, 'fixProp': 0.7156335951424408}\n","Val loss 0.009512856765650213 and Val R2 {'nFix': 0.5942424394214866, 'FFD': 0.5722133921270997, 'GPT': 0.5412254686318612, 'TRT': 0.562630608317938, 'fixProp': 0.6480813984323536}\n","\n","EarlyStopping counter: 1 out of 8\n","Epoch 7/120\n","------------------------------------------------------------------------------------------------------------------------\n","Train loss 0.011656261212192476 and Train R2 {'nFix': 0.7610583823749671, 'FFD': 0.6597062339461193, 'GPT': 0.44751213494681485, 'TRT': 0.7414548482850372, 'fixProp': 0.7049236288688105}\n","Val loss 0.009477022336795926 and Val R2 {'nFix': 0.6086103277440953, 'FFD': 0.582896707433459, 'GPT': 0.5445635085685772, 'TRT': 0.5758377922241624, 'fixProp': 0.6542934297375813}\n","\n","EarlyStopping counter: 2 out of 8\n","Epoch 8/120\n","------------------------------------------------------------------------------------------------------------------------\n","Train loss 0.011614054441452026 and Train R2 {'nFix': 0.7491190974954414, 'FFD': 0.666742357148997, 'GPT': 0.46033749929289336, 'TRT': 0.7476842549215847, 'fixProp': 0.7268313839464313}\n","Val loss 0.009412215929478407 and Val R2 {'nFix': 0.6176013770594858, 'FFD': 0.5855424915313944, 'GPT': 0.5449287276040274, 'TRT': 0.5824435891669213, 'fixProp': 0.6524453478008589}\n","\n","Validation loss decreased (0.009433 --> 0.009412).  Saving model ...\n","Epoch 9/120\n","------------------------------------------------------------------------------------------------------------------------\n","Train loss 0.011541849363129585 and Train R2 {'nFix': 0.767846480108526, 'FFD': 0.6754395734699585, 'GPT': 0.4468989691716937, 'TRT': 0.7553989196268088, 'fixProp': 0.7180088638137052}\n","Val loss 0.009418691275641322 and Val R2 {'nFix': 0.6087679275234713, 'FFD': 0.5872696456917269, 'GPT': 0.5471397906375237, 'TRT': 0.5728375086648163, 'fixProp': 0.6545443790158907}\n","\n","EarlyStopping counter: 1 out of 8\n","Epoch 10/120\n","------------------------------------------------------------------------------------------------------------------------\n","Train loss 0.011559253197629005 and Train R2 {'nFix': 0.7504103346279393, 'FFD': 0.6697900758424423, 'GPT': 0.467534713183014, 'TRT': 0.7412580377774272, 'fixProp': 0.7187097748580462}\n","Val loss 0.00941459487657994 and Val R2 {'nFix': 0.6054524797147824, 'FFD': 0.5896788966227253, 'GPT': 0.5470058092643919, 'TRT': 0.5753040595707919, 'fixProp': 0.6501326558013538}\n","\n","EarlyStopping counter: 2 out of 8\n","Epoch 11/120\n","------------------------------------------------------------------------------------------------------------------------\n","Train loss 0.011538899107836186 and Train R2 {'nFix': 0.7635651474251198, 'FFD': 0.6546191727794746, 'GPT': 0.44842223740763265, 'TRT': 0.7386250698064504, 'fixProp': 0.7100848164067338}\n","Val loss 0.009518041275441647 and Val R2 {'nFix': 0.5979762701502701, 'FFD': 0.5763001540653357, 'GPT': 0.5459322975915791, 'TRT': 0.5697665668603702, 'fixProp': 0.6494791870913781}\n","\n","EarlyStopping counter: 3 out of 8\n","Epoch 12/120\n","------------------------------------------------------------------------------------------------------------------------\n","Train loss 0.011530743842013181 and Train R2 {'nFix': 0.7536984346364719, 'FFD': 0.6759929906206896, 'GPT': 0.4400821409453135, 'TRT': 0.7488142737553689, 'fixProp': 0.720416075708825}\n","Val loss 0.009422010835260152 and Val R2 {'nFix': 0.599792531857069, 'FFD': 0.581158923453015, 'GPT': 0.544497195459277, 'TRT': 0.568960955087823, 'fixProp': 0.6530369621221592}\n","\n","EarlyStopping counter: 4 out of 8\n","Epoch 13/120\n","------------------------------------------------------------------------------------------------------------------------\n","Train loss 0.011548209155444055 and Train R2 {'nFix': 0.7658666720433069, 'FFD': 0.6646768013728641, 'GPT': 0.45839316683385245, 'TRT': 0.7466514056404678, 'fixProp': 0.7317857186125319}\n","Val loss 0.009405397903174162 and Val R2 {'nFix': 0.5963288235866229, 'FFD': 0.5807564839553454, 'GPT': 0.535511703596555, 'TRT': 0.5599116233231805, 'fixProp': 0.6514786437406005}\n","\n","Validation loss decreased (0.009412 --> 0.009405).  Saving model ...\n","Epoch 14/120\n","------------------------------------------------------------------------------------------------------------------------\n","Train loss 0.011441739089787007 and Train R2 {'nFix': 0.7710817063921099, 'FFD': 0.6741714474939071, 'GPT': 0.4446285153250543, 'TRT': 0.7546717021901699, 'fixProp': 0.7132246404403365}\n","Val loss 0.00933072534389794 and Val R2 {'nFix': 0.5990504508345502, 'FFD': 0.5847023730101232, 'GPT': 0.5416893416584957, 'TRT': 0.5685659629825776, 'fixProp': 0.6524345185768038}\n","\n","Validation loss decreased (0.009405 --> 0.009331).  Saving model ...\n","Epoch 15/120\n","------------------------------------------------------------------------------------------------------------------------\n","Train loss 0.011312484205700458 and Train R2 {'nFix': 0.7651349627003596, 'FFD': 0.677902128928026, 'GPT': 0.45123990212691045, 'TRT': 0.7561335663387683, 'fixProp': 0.7243046621921203}\n","Val loss 0.009403727925382554 and Val R2 {'nFix': 0.5992824896530424, 'FFD': 0.580437999485327, 'GPT': 0.5397333600061225, 'TRT': 0.5674952025320594, 'fixProp': 0.648686799113714}\n","\n","EarlyStopping counter: 1 out of 8\n","Epoch 16/120\n","------------------------------------------------------------------------------------------------------------------------\n","Train loss 0.011323738575447351 and Train R2 {'nFix': 0.7658935593152103, 'FFD': 0.6949306738018415, 'GPT': 0.46412346662918025, 'TRT': 0.7602975388562103, 'fixProp': 0.7271248276144483}\n","Val loss 0.009387422585859895 and Val R2 {'nFix': 0.6107916814849661, 'FFD': 0.5881035189604824, 'GPT': 0.5452361233409009, 'TRT': 0.5800326706130331, 'fixProp': 0.6507212494234456}\n","\n","EarlyStopping counter: 2 out of 8\n","Epoch 17/120\n","------------------------------------------------------------------------------------------------------------------------\n","Train loss 0.011343991220928728 and Train R2 {'nFix': 0.7768794795948587, 'FFD': 0.6789784606917653, 'GPT': 0.46521265929392575, 'TRT': 0.7548020361903888, 'fixProp': 0.7201319458255366}\n","Val loss 0.009425448672845959 and Val R2 {'nFix': 0.6056474312703508, 'FFD': 0.5870489503148806, 'GPT': 0.5446515228229125, 'TRT': 0.5712231601201556, 'fixProp': 0.6514537135162248}\n","\n","EarlyStopping counter: 3 out of 8\n","Epoch 18/120\n","------------------------------------------------------------------------------------------------------------------------\n","Train loss 0.011337008117698133 and Train R2 {'nFix': 0.7727050705006804, 'FFD': 0.6776401736899273, 'GPT': 0.4531319566450963, 'TRT': 0.7518674397484671, 'fixProp': 0.7224718414469666}\n","Val loss 0.009399724728427827 and Val R2 {'nFix': 0.6066483424391931, 'FFD': 0.5759270027260756, 'GPT': 0.5449534342621107, 'TRT': 0.5723473227486575, 'fixProp': 0.6484780510340821}\n","\n","EarlyStopping counter: 4 out of 8\n","Epoch 19/120\n","------------------------------------------------------------------------------------------------------------------------\n","Train loss 0.011347680701874197 and Train R2 {'nFix': 0.762735446081493, 'FFD': 0.674303472113364, 'GPT': 0.4447187005119012, 'TRT': 0.7484387879507726, 'fixProp': 0.7159957050020263}\n","Val loss 0.009361368557438254 and Val R2 {'nFix': 0.6120948945328468, 'FFD': 0.5870250733507534, 'GPT': 0.5434306066069511, 'TRT': 0.5815042760761715, 'fixProp': 0.6558581120116603}\n","\n","EarlyStopping counter: 5 out of 8\n","Epoch 20/120\n","------------------------------------------------------------------------------------------------------------------------\n","Train loss 0.011312068242114037 and Train R2 {'nFix': 0.7723403506735389, 'FFD': 0.6904594491424305, 'GPT': 0.4564057883646897, 'TRT': 0.7659597158128058, 'fixProp': 0.7258949800824503}\n","Val loss 0.009392005670815707 and Val R2 {'nFix': 0.6107445642590464, 'FFD': 0.5817019314319778, 'GPT': 0.54132941803051, 'TRT': 0.5805910712985027, 'fixProp': 0.6534059292570347}\n","\n","EarlyStopping counter: 6 out of 8\n","Epoch 21/120\n","------------------------------------------------------------------------------------------------------------------------\n","Train loss 0.011377079191152006 and Train R2 {'nFix': 0.7688276243333312, 'FFD': 0.6796983980636303, 'GPT': 0.4642306267140318, 'TRT': 0.7434717625787183, 'fixProp': 0.7315816044761263}\n","Val loss 0.009396826615557075 and Val R2 {'nFix': 0.6099065648848789, 'FFD': 0.5828915670511128, 'GPT': 0.5393328324311268, 'TRT': 0.5753650895646183, 'fixProp': 0.6508265787335352}\n","\n","EarlyStopping counter: 7 out of 8\n","Epoch 22/120\n","------------------------------------------------------------------------------------------------------------------------\n","Train loss 0.011339097074232996 and Train R2 {'nFix': 0.768058222297522, 'FFD': 0.6901693639327009, 'GPT': 0.45376491742060665, 'TRT': 0.7624337384113574, 'fixProp': 0.7367490851595606}\n","Val loss 0.009438178059644997 and Val R2 {'nFix': 0.6071858742616043, 'FFD': 0.5833783840887317, 'GPT': 0.5419849396853922, 'TRT': 0.5752082077775751, 'fixProp': 0.6472324141379966}\n","\n","EarlyStopping counter: 8 out of 8\n","Stopped Early at at Epoch  22\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bXq0k8_FuX36","colab":{"base_uri":"https://localhost:8080/","height":280},"executionInfo":{"status":"ok","timestamp":1614416077075,"user_tz":-330,"elapsed":833220,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"4c713efd-da91-473d-fcbd-b75041efeaf1"},"source":["plt.plot(history[\"train_loss\"], c = \"r\", label = \"Train Loss\")\n","plt.plot(history[\"val_loss\"], c = \"g\", label = \"Validation Loss\")\n","plt.legend()\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"L1 Loss\")\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"2a01UuYhsaqf"},"source":["plt.plot(history[\"train_nFix\"], c = \"r\", label = \"Train Loss\")\n","plt.plot(history[\"val_nFix\"], c = \"g\", label = \"Validation Loss\")\n","plt.legend()\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"nFix R2\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cmdo1mvZ2EZu"},"source":["plt.plot(history[\"train_FFD\"], c = \"r\", label = \"Train Loss\")\n","plt.plot(history[\"val_FFD\"], c = \"g\", label = \"Validation Loss\")\n","plt.legend()\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"FFD R2\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rJHdVFTP2Elc"},"source":["plt.plot(history[\"train_GPT\"], c = \"r\", label = \"Train Loss\")\n","plt.plot(history[\"val_GPT\"], c = \"g\", label = \"Validation Loss\")\n","plt.legend()\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"GPT R2\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1JbTNzVD2E0I"},"source":["plt.plot(history[\"train_TRT\"], c = \"r\", label = \"Train Loss\")\n","plt.plot(history[\"val_TRT\"], c = \"g\", label = \"Validation Loss\")\n","plt.legend()\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"TRT R2\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4aQVAHfL2Feb"},"source":["plt.plot(history[\"train_fixProp\"], c = \"r\", label = \"Train Loss\")\n","plt.plot(history[\"val_fixProp\"], c = \"g\", label = \"Validation Loss\")\n","plt.legend()\n","plt.xlabel(\"Epochs\")\n","plt.ylabel(\"fixProp R2\")\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8dEi49j1uX0k"},"source":["train_arr = np.array([best[\"train_nFix\"], best[\"train_FFD\"], best[\"train_GPT\"], best[\"train_TRT\"], best[\"train_fixProp\"]])\n","val_arr = np.array([best[\"val_nFix\"], best[\"val_FFD\"], best[\"val_GPT\"], best[\"val_TRT\"], best[\"val_fixProp\"]])\n","\n","train_mean = np.mean(train_arr)\n","train_std = np.std(train_arr)\n","train_M = np.max(train_arr)\n","train_m = np.min(train_arr)\n","val_mean = np.mean(val_arr)\n","val_std = np.std(val_arr)\n","val_M = np.max(val_arr)\n","val_m = np.min(val_arr)\n","\n","display_data = [[best[\"train_loss\"], best[\"train_nFix\"], best[\"train_FFD\"], best[\"train_GPT\"], best[\"train_TRT\"], best[\"train_fixProp\"], train_mean, train_std, train_M, train_m],\n"," [best[\"val_loss\"], best[\"val_nFix\"], best[\"val_FFD\"], best[\"val_GPT\"], best[\"val_TRT\"], best[\"val_fixProp\"], val_mean, val_std, val_M, val_m]]\n","\n","display_df = pd.DataFrame(display_data, columns = [\"L1Loss\", \"nFix\", \"FFD\", \"GPT\", \"TRT\", \"fixProp\", \"Mean\", \"Std Deviation\", \"Max\", \"Min\"], index = [\"Train\", \"Val\"]) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"FNm1xrc-as7a","colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"status":"ok","timestamp":1614416077773,"user_tz":-330,"elapsed":826851,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"2dc706af-662d-4114-e308-601eca990dbc"},"source":["display_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>L1Loss</th>\n","      <th>nFix</th>\n","      <th>FFD</th>\n","      <th>GPT</th>\n","      <th>TRT</th>\n","      <th>fixProp</th>\n","      <th>Mean</th>\n","      <th>Std Deviation</th>\n","      <th>Max</th>\n","      <th>Min</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Train</th>\n","      <td>0.011442</td>\n","      <td>0.771082</td>\n","      <td>0.674171</td>\n","      <td>0.444629</td>\n","      <td>0.754672</td>\n","      <td>0.713225</td>\n","      <td>0.671556</td>\n","      <td>0.118366</td>\n","      <td>0.771082</td>\n","      <td>0.444629</td>\n","    </tr>\n","    <tr>\n","      <th>Val</th>\n","      <td>0.009331</td>\n","      <td>0.599050</td>\n","      <td>0.584702</td>\n","      <td>0.541689</td>\n","      <td>0.568566</td>\n","      <td>0.652435</td>\n","      <td>0.589289</td>\n","      <td>0.036875</td>\n","      <td>0.652435</td>\n","      <td>0.541689</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         L1Loss      nFix       FFD  ...  Std Deviation       Max       Min\n","Train  0.011442  0.771082  0.674171  ...       0.118366  0.771082  0.444629\n","Val    0.009331  0.599050  0.584702  ...       0.036875  0.652435  0.541689\n","\n","[2 rows x 10 columns]"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jwKCqWuug2q6","executionInfo":{"status":"ok","timestamp":1614429718283,"user_tz":-330,"elapsed":35659,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"fae0d482-e4bc-4d68-e48f-892313092589"},"source":["predictions = predict_model(model, test_data_loader, device)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Calculating Predictions on Test Set...\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9qlTRTdM3_bM","executionInfo":{"status":"ok","timestamp":1614429729617,"user_tz":-330,"elapsed":944,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"764aad18-a436-4002-878b-e4f016c0a7bb"},"source":["print(test_df.shape)\n","np.array(predictions).shape"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(3554, 19)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["(3554, 5)"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":404},"id":"uBc-EixLW64C","executionInfo":{"status":"ok","timestamp":1614429842002,"user_tz":-330,"elapsed":1002,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"c64c08d0-55e1-4847-fa8e-fd5d74f50f4f"},"source":["preds = pd.DataFrame(predictions, columns = [\"nFix\", \"FFD\", \"GPT\", \"TRT\", \"fixProp\"])\n","preds"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>nFix</th>\n","      <th>FFD</th>\n","      <th>GPT</th>\n","      <th>TRT</th>\n","      <th>fixProp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-0.689254</td>\n","      <td>0.413951</td>\n","      <td>0.298920</td>\n","      <td>-0.043348</td>\n","      <td>0.363724</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-0.518733</td>\n","      <td>0.411733</td>\n","      <td>0.238509</td>\n","      <td>-0.030873</td>\n","      <td>0.160814</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-0.513367</td>\n","      <td>0.414767</td>\n","      <td>0.367185</td>\n","      <td>-0.059593</td>\n","      <td>0.463832</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>-0.632751</td>\n","      <td>0.385030</td>\n","      <td>0.338632</td>\n","      <td>-0.006572</td>\n","      <td>0.375303</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>-0.609731</td>\n","      <td>0.374420</td>\n","      <td>0.334197</td>\n","      <td>-0.025055</td>\n","      <td>0.340712</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3549</th>\n","      <td>-0.637447</td>\n","      <td>0.357076</td>\n","      <td>0.304080</td>\n","      <td>0.049192</td>\n","      <td>0.319407</td>\n","    </tr>\n","    <tr>\n","      <th>3550</th>\n","      <td>-0.614143</td>\n","      <td>0.405309</td>\n","      <td>0.397816</td>\n","      <td>-0.108933</td>\n","      <td>0.457709</td>\n","    </tr>\n","    <tr>\n","      <th>3551</th>\n","      <td>-0.693736</td>\n","      <td>0.387371</td>\n","      <td>0.315741</td>\n","      <td>0.037042</td>\n","      <td>0.386127</td>\n","    </tr>\n","    <tr>\n","      <th>3552</th>\n","      <td>-0.617522</td>\n","      <td>0.447106</td>\n","      <td>0.366848</td>\n","      <td>-0.013568</td>\n","      <td>0.429471</td>\n","    </tr>\n","    <tr>\n","      <th>3553</th>\n","      <td>-0.337404</td>\n","      <td>0.398617</td>\n","      <td>0.319438</td>\n","      <td>-0.170073</td>\n","      <td>0.183378</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3554 rows × 5 columns</p>\n","</div>"],"text/plain":["          nFix       FFD       GPT       TRT   fixProp\n","0    -0.689254  0.413951  0.298920 -0.043348  0.363724\n","1    -0.518733  0.411733  0.238509 -0.030873  0.160814\n","2    -0.513367  0.414767  0.367185 -0.059593  0.463832\n","3    -0.632751  0.385030  0.338632 -0.006572  0.375303\n","4    -0.609731  0.374420  0.334197 -0.025055  0.340712\n","...        ...       ...       ...       ...       ...\n","3549 -0.637447  0.357076  0.304080  0.049192  0.319407\n","3550 -0.614143  0.405309  0.397816 -0.108933  0.457709\n","3551 -0.693736  0.387371  0.315741  0.037042  0.386127\n","3552 -0.617522  0.447106  0.366848 -0.013568  0.429471\n","3553 -0.337404  0.398617  0.319438 -0.170073  0.183378\n","\n","[3554 rows x 5 columns]"]},"metadata":{"tags":[]},"execution_count":43}]},{"cell_type":"code","metadata":{"id":"sWWT6fGs0NrC"},"source":["#preds = preds*10\n","std_scaler = pickle.load(open(\"/content/drive/My Drive/CMCL Shared Task/StandardScaler.pkl\", \"rb\"))\n","final_preds = stdwe_scaler.inverse_transform(preds)\n","final_preds[\"GPT\"] = final_preds[\"TRT\"] - final_preds[\"GPT\"]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eTXqp9X40b20","executionInfo":{"status":"ok","timestamp":1614429846024,"user_tz":-330,"elapsed":665,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"f2e10568-20b5-46dc-e141-805cddc083ab"},"source":["final_preds"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 8.60585021,  3.77983321,  0.38293486,  5.15175717, 76.53553052],\n","       [10.21293595,  3.77667871,  0.09619011,  5.19718658, 71.24787934],\n","       [10.26351186,  3.78099376,  0.70695643,  5.09260119, 79.1442304 ],\n","       ...,\n","       [ 8.56361177,  3.74202534,  0.46277506,  5.44449713, 77.11931213],\n","       [ 9.28189385,  3.82699299,  0.70535795,  5.2602026 , 78.24881944],\n","       [11.92188975,  3.758022  ,  0.48032149,  4.690289  , 71.83587721]])"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GkniAMA4hK5n","executionInfo":{"status":"ok","timestamp":1614429904825,"user_tz":-330,"elapsed":995,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"db000ae0-4812-4a83-de9a-ae7d67f7eefa"},"source":["np.max(final_preds, axis = 0)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([15.14243767,  4.03768468,  1.37164024,  6.13845193, 83.72286857])"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":404},"id":"A7ZYSxm31svQ","executionInfo":{"status":"ok","timestamp":1614429947750,"user_tz":-330,"elapsed":1346,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"04c21d4f-cb54-49e4-b8bc-b69af2ecbd45"},"source":["pred_df = pd.DataFrame(final_preds, columns = [\"nFix\", \"FFD\", \"GPT\", \"TRT\", \"fixProp\"])\n","test_dataset = pd.read_csv(\"/content/drive/My Drive/CMCL Shared Task/test_data.csv\")\n","submission = pd.concat((test_dataset, pred_df), axis = 1)\n","submission"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence_id</th>\n","      <th>word_id</th>\n","      <th>word</th>\n","      <th>nFix</th>\n","      <th>FFD</th>\n","      <th>GPT</th>\n","      <th>TRT</th>\n","      <th>fixProp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>800</td>\n","      <td>0</td>\n","      <td>It's</td>\n","      <td>8.605850</td>\n","      <td>3.779833</td>\n","      <td>0.382935</td>\n","      <td>5.151757</td>\n","      <td>76.535531</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>800</td>\n","      <td>1</td>\n","      <td>the</td>\n","      <td>10.212936</td>\n","      <td>3.776679</td>\n","      <td>0.096190</td>\n","      <td>5.197187</td>\n","      <td>71.247879</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>800</td>\n","      <td>2</td>\n","      <td>funniest</td>\n","      <td>10.263512</td>\n","      <td>3.780994</td>\n","      <td>0.706956</td>\n","      <td>5.092601</td>\n","      <td>79.144230</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>800</td>\n","      <td>3</td>\n","      <td>American</td>\n","      <td>9.138371</td>\n","      <td>3.738696</td>\n","      <td>0.571428</td>\n","      <td>5.285676</td>\n","      <td>76.837258</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>800</td>\n","      <td>4</td>\n","      <td>comedy</td>\n","      <td>9.355318</td>\n","      <td>3.723604</td>\n","      <td>0.550379</td>\n","      <td>5.218373</td>\n","      <td>75.935859</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3549</th>\n","      <td>990</td>\n","      <td>5</td>\n","      <td>pursued</td>\n","      <td>9.094110</td>\n","      <td>3.698933</td>\n","      <td>0.407425</td>\n","      <td>5.488741</td>\n","      <td>75.380662</td>\n","    </tr>\n","    <tr>\n","      <th>3550</th>\n","      <td>990</td>\n","      <td>6</td>\n","      <td>a</td>\n","      <td>9.313741</td>\n","      <td>3.767540</td>\n","      <td>0.852347</td>\n","      <td>4.912932</td>\n","      <td>78.984682</td>\n","    </tr>\n","    <tr>\n","      <th>3551</th>\n","      <td>990</td>\n","      <td>7</td>\n","      <td>career</td>\n","      <td>8.563612</td>\n","      <td>3.742025</td>\n","      <td>0.462775</td>\n","      <td>5.444497</td>\n","      <td>77.119312</td>\n","    </tr>\n","    <tr>\n","      <th>3552</th>\n","      <td>990</td>\n","      <td>8</td>\n","      <td>in</td>\n","      <td>9.281894</td>\n","      <td>3.826993</td>\n","      <td>0.705358</td>\n","      <td>5.260203</td>\n","      <td>78.248819</td>\n","    </tr>\n","    <tr>\n","      <th>3553</th>\n","      <td>990</td>\n","      <td>9</td>\n","      <td>politics.&lt;EOS&gt;</td>\n","      <td>11.921890</td>\n","      <td>3.758022</td>\n","      <td>0.480321</td>\n","      <td>4.690289</td>\n","      <td>71.835877</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3554 rows × 8 columns</p>\n","</div>"],"text/plain":["      sentence_id  word_id            word  ...       GPT       TRT    fixProp\n","0             800        0            It's  ...  0.382935  5.151757  76.535531\n","1             800        1             the  ...  0.096190  5.197187  71.247879\n","2             800        2        funniest  ...  0.706956  5.092601  79.144230\n","3             800        3        American  ...  0.571428  5.285676  76.837258\n","4             800        4          comedy  ...  0.550379  5.218373  75.935859\n","...           ...      ...             ...  ...       ...       ...        ...\n","3549          990        5         pursued  ...  0.407425  5.488741  75.380662\n","3550          990        6               a  ...  0.852347  4.912932  78.984682\n","3551          990        7          career  ...  0.462775  5.444497  77.119312\n","3552          990        8              in  ...  0.705358  5.260203  78.248819\n","3553          990        9  politics.<EOS>  ...  0.480321  4.690289  71.835877\n","\n","[3554 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":49}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":703},"id":"Umt4Qa4khhB5","executionInfo":{"status":"ok","timestamp":1614430099499,"user_tz":-330,"elapsed":1112,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"7069c975-0f06-4d97-bfb1-421cecfbd56a"},"source":["submission[submission.sentence_id == 804]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence_id</th>\n","      <th>word_id</th>\n","      <th>word</th>\n","      <th>nFix</th>\n","      <th>FFD</th>\n","      <th>GPT</th>\n","      <th>TRT</th>\n","      <th>fixProp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>42</th>\n","      <td>804</td>\n","      <td>0</td>\n","      <td>Despite</td>\n","      <td>9.370315</td>\n","      <td>3.794903</td>\n","      <td>0.700830</td>\n","      <td>4.615272</td>\n","      <td>79.980623</td>\n","    </tr>\n","    <tr>\n","      <th>43</th>\n","      <td>804</td>\n","      <td>1</td>\n","      <td>the</td>\n","      <td>12.659504</td>\n","      <td>3.784085</td>\n","      <td>0.665945</td>\n","      <td>4.019638</td>\n","      <td>72.972011</td>\n","    </tr>\n","    <tr>\n","      <th>44</th>\n","      <td>804</td>\n","      <td>2</td>\n","      <td>holes</td>\n","      <td>9.977493</td>\n","      <td>3.741667</td>\n","      <td>0.913090</td>\n","      <td>5.170181</td>\n","      <td>77.791478</td>\n","    </tr>\n","    <tr>\n","      <th>45</th>\n","      <td>804</td>\n","      <td>3</td>\n","      <td>in</td>\n","      <td>11.012003</td>\n","      <td>3.695837</td>\n","      <td>0.183687</td>\n","      <td>4.925866</td>\n","      <td>73.186584</td>\n","    </tr>\n","    <tr>\n","      <th>46</th>\n","      <td>804</td>\n","      <td>4</td>\n","      <td>the</td>\n","      <td>9.820129</td>\n","      <td>3.793923</td>\n","      <td>0.909712</td>\n","      <td>4.912590</td>\n","      <td>79.763415</td>\n","    </tr>\n","    <tr>\n","      <th>47</th>\n","      <td>804</td>\n","      <td>5</td>\n","      <td>story</td>\n","      <td>10.027016</td>\n","      <td>3.759248</td>\n","      <td>0.134972</td>\n","      <td>5.288961</td>\n","      <td>70.790613</td>\n","    </tr>\n","    <tr>\n","      <th>48</th>\n","      <td>804</td>\n","      <td>6</td>\n","      <td>and</td>\n","      <td>9.155048</td>\n","      <td>3.737464</td>\n","      <td>0.638026</td>\n","      <td>5.172631</td>\n","      <td>77.589631</td>\n","    </tr>\n","    <tr>\n","      <th>49</th>\n","      <td>804</td>\n","      <td>7</td>\n","      <td>the</td>\n","      <td>10.048340</td>\n","      <td>3.724815</td>\n","      <td>-0.126054</td>\n","      <td>5.009635</td>\n","      <td>73.527836</td>\n","    </tr>\n","    <tr>\n","      <th>50</th>\n","      <td>804</td>\n","      <td>8</td>\n","      <td>somewhat</td>\n","      <td>10.691073</td>\n","      <td>3.757172</td>\n","      <td>0.320100</td>\n","      <td>5.032669</td>\n","      <td>69.550100</td>\n","    </tr>\n","    <tr>\n","      <th>51</th>\n","      <td>804</td>\n","      <td>9</td>\n","      <td>predictable</td>\n","      <td>12.143919</td>\n","      <td>3.748824</td>\n","      <td>0.543408</td>\n","      <td>4.045014</td>\n","      <td>72.289664</td>\n","    </tr>\n","    <tr>\n","      <th>52</th>\n","      <td>804</td>\n","      <td>10</td>\n","      <td>plot,</td>\n","      <td>8.961577</td>\n","      <td>3.731259</td>\n","      <td>0.374916</td>\n","      <td>5.433564</td>\n","      <td>76.285444</td>\n","    </tr>\n","    <tr>\n","      <th>53</th>\n","      <td>804</td>\n","      <td>11</td>\n","      <td>moments</td>\n","      <td>10.683373</td>\n","      <td>3.660860</td>\n","      <td>0.049391</td>\n","      <td>4.888659</td>\n","      <td>73.262959</td>\n","    </tr>\n","    <tr>\n","      <th>54</th>\n","      <td>804</td>\n","      <td>12</td>\n","      <td>of</td>\n","      <td>8.774875</td>\n","      <td>3.775168</td>\n","      <td>0.320648</td>\n","      <td>5.735144</td>\n","      <td>75.002601</td>\n","    </tr>\n","    <tr>\n","      <th>55</th>\n","      <td>804</td>\n","      <td>13</td>\n","      <td>the</td>\n","      <td>8.239637</td>\n","      <td>3.726578</td>\n","      <td>0.340042</td>\n","      <td>5.380896</td>\n","      <td>77.788491</td>\n","    </tr>\n","    <tr>\n","      <th>56</th>\n","      <td>804</td>\n","      <td>14</td>\n","      <td>movie</td>\n","      <td>8.751837</td>\n","      <td>3.770303</td>\n","      <td>0.437211</td>\n","      <td>5.417195</td>\n","      <td>76.449470</td>\n","    </tr>\n","    <tr>\n","      <th>57</th>\n","      <td>804</td>\n","      <td>15</td>\n","      <td>caused</td>\n","      <td>9.059427</td>\n","      <td>3.720062</td>\n","      <td>0.245518</td>\n","      <td>4.706699</td>\n","      <td>76.059654</td>\n","    </tr>\n","    <tr>\n","      <th>58</th>\n","      <td>804</td>\n","      <td>16</td>\n","      <td>me</td>\n","      <td>12.823819</td>\n","      <td>3.754085</td>\n","      <td>0.926170</td>\n","      <td>3.682790</td>\n","      <td>70.002358</td>\n","    </tr>\n","    <tr>\n","      <th>59</th>\n","      <td>804</td>\n","      <td>17</td>\n","      <td>to</td>\n","      <td>14.742197</td>\n","      <td>3.525970</td>\n","      <td>0.906892</td>\n","      <td>3.967167</td>\n","      <td>72.365148</td>\n","    </tr>\n","    <tr>\n","      <th>60</th>\n","      <td>804</td>\n","      <td>18</td>\n","      <td>jump</td>\n","      <td>14.075739</td>\n","      <td>3.607412</td>\n","      <td>0.962962</td>\n","      <td>3.899358</td>\n","      <td>70.968029</td>\n","    </tr>\n","    <tr>\n","      <th>61</th>\n","      <td>804</td>\n","      <td>19</td>\n","      <td>in</td>\n","      <td>13.300305</td>\n","      <td>3.767982</td>\n","      <td>1.027791</td>\n","      <td>3.874221</td>\n","      <td>72.143856</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>804</td>\n","      <td>20</td>\n","      <td>my</td>\n","      <td>12.455323</td>\n","      <td>3.763677</td>\n","      <td>0.929234</td>\n","      <td>3.443188</td>\n","      <td>68.282327</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>804</td>\n","      <td>21</td>\n","      <td>chair...&lt;EOS&gt;</td>\n","      <td>13.307192</td>\n","      <td>3.787851</td>\n","      <td>0.974016</td>\n","      <td>3.751246</td>\n","      <td>70.210237</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    sentence_id  word_id           word  ...       GPT       TRT    fixProp\n","42          804        0        Despite  ...  0.700830  4.615272  79.980623\n","43          804        1            the  ...  0.665945  4.019638  72.972011\n","44          804        2          holes  ...  0.913090  5.170181  77.791478\n","45          804        3             in  ...  0.183687  4.925866  73.186584\n","46          804        4            the  ...  0.909712  4.912590  79.763415\n","47          804        5          story  ...  0.134972  5.288961  70.790613\n","48          804        6            and  ...  0.638026  5.172631  77.589631\n","49          804        7            the  ... -0.126054  5.009635  73.527836\n","50          804        8       somewhat  ...  0.320100  5.032669  69.550100\n","51          804        9    predictable  ...  0.543408  4.045014  72.289664\n","52          804       10          plot,  ...  0.374916  5.433564  76.285444\n","53          804       11        moments  ...  0.049391  4.888659  73.262959\n","54          804       12             of  ...  0.320648  5.735144  75.002601\n","55          804       13            the  ...  0.340042  5.380896  77.788491\n","56          804       14          movie  ...  0.437211  5.417195  76.449470\n","57          804       15         caused  ...  0.245518  4.706699  76.059654\n","58          804       16             me  ...  0.926170  3.682790  70.002358\n","59          804       17             to  ...  0.906892  3.967167  72.365148\n","60          804       18           jump  ...  0.962962  3.899358  70.968029\n","61          804       19             in  ...  1.027791  3.874221  72.143856\n","62          804       20             my  ...  0.929234  3.443188  68.282327\n","63          804       21  chair...<EOS>  ...  0.974016  3.751246  70.210237\n","\n","[22 rows x 8 columns]"]},"metadata":{"tags":[]},"execution_count":56}]},{"cell_type":"code","metadata":{"id":"cti_HYnr5E0S"},"source":["s = ''\n","for column in submission.columns:\n","  s += str(column)\n","  s += \",\"\n","s = s[:-1]\n","s += \"\\n\"\n","with open(\"/content/drive/My Drive/CMCL Shared Task/roberta_features_twotraining_submission.txt\", 'w') as f:\n","    v = ''\n","    f.write(s)\n","    x = submission.to_string(header=False,\n","                  index=False,\n","                  index_names=False).split('\\n')\n","    vals = [','.join(ele.split()) for ele in x]\n","    for val in vals:\n","      v += str(val)\n","      v += \"\\n\"\n","    f.write(\n","        v\n","    )\n","    f.close()\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Qbg7_c4A0PGi"},"source":["display_data2 = [[history[\"train_loss\"][-1], history[\"train_nFix\"][-1], history[\"train_FFD\"][-1], history[\"train_GPT\"][-1], history[\"train_TRT\"][-1], history[\"train_fixProp\"][-1]], \n","                 [history[\"val_loss\"][-1], history[\"val_nFix\"][-1], history[\"val_FFD\"][-1], history[\"val_GPT\"][-1], history[\"val_TRT\"][-1], history[\"val_fixProp\"][-1]]]\n","display_df2 = pd.DataFrame(display_data2, columns = [\"L1Loss\", \"nFix\", \"FFD\", \"GPT\", \"TRT\", \"fixProp\"], index = [\"Train \", \"Val \"]) "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LSMzdfBm07XO","colab":{"base_uri":"https://localhost:8080/","height":107},"executionInfo":{"status":"ok","timestamp":1614416082403,"user_tz":-330,"elapsed":2083,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"727b731a-63a9-4e25-99f0-32f03fc4ea54"},"source":["display_df2"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>L1Loss</th>\n","      <th>nFix</th>\n","      <th>FFD</th>\n","      <th>GPT</th>\n","      <th>TRT</th>\n","      <th>fixProp</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Train</th>\n","      <td>0.011339</td>\n","      <td>0.768058</td>\n","      <td>0.690169</td>\n","      <td>0.453765</td>\n","      <td>0.762434</td>\n","      <td>0.736749</td>\n","    </tr>\n","    <tr>\n","      <th>Val</th>\n","      <td>0.009438</td>\n","      <td>0.607186</td>\n","      <td>0.583378</td>\n","      <td>0.541985</td>\n","      <td>0.575208</td>\n","      <td>0.647232</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          L1Loss      nFix       FFD       GPT       TRT   fixProp\n","Train   0.011339  0.768058  0.690169  0.453765  0.762434  0.736749\n","Val     0.009438  0.607186  0.583378  0.541985  0.575208  0.647232"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"t1i0WDWv94G1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614416082404,"user_tz":-330,"elapsed":2082,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"a2a71430-15db-44fa-c65a-74b1801c1364"},"source":["history[\"train_loss\"][0], history[\"val_loss\"][0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.011920027318410575, 0.00948275316040963)"]},"metadata":{"tags":[]},"execution_count":59}]},{"cell_type":"code","metadata":{"id":"pGajW6WtuNU6"},"source":["save_file_path = \"/content/drive/My Drive/CMCL Shared Task/Full_RoBerta_Features_twotraining_23.pth\"\n","torch.save(model.state_dict(), save_file_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"agccWlGCiiIy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1614429556408,"user_tz":-330,"elapsed":1790,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"a720fa29-3bf8-44bf-d924-9837eeaccecf"},"source":["save_file_path = \"/content/drive/My Drive/CMCL Shared Task/Full_RoBerta_Features_twotraining_23.pth\"\n","model.load_state_dict(torch.load(save_file_path, map_location = torch.device(\"cpu\")))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"vIeelTiukhhV"},"source":["## SUBMISSION CODE ENDS HERE"]},{"cell_type":"code","metadata":{"id":"lddzhwV8Xkru"},"source":["MAX_LEN = 95\n","std_scaler = pickle.load(open(\"/content/drive/My Drive/CMCL Shared Task/StandardScaler.pkl\", \"rb\"))\n","vectorizer = pickle.load(open(\"/content/drive/My Drive/CMCL Shared Task/TfIdfVectorizer.pkl\", \"rb\"))\n","enc = pickle.load(open(\"/content/drive/My Drive/CMCL Shared Task/OneHotEncoder.pkl\", \"rb\"))\n","\n","\n","test_df, test_sentences, _, test_MAX_LEN = preprocess(test_data)\n","print(\"Test Max Len \", test_MAX_LEN)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"Q9tIpwdLpKwP","executionInfo":{"status":"ok","timestamp":1614230632470,"user_tz":-330,"elapsed":1362,"user":{"displayName":"Shraman Pal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GitFpHrw98FuHPGTmkI8kD-i-meVum9Ci9XvEGa=s64","userId":"16081828426227827314"}},"outputId":"475a7a1f-da5f-4fd6-e837-a24cf08c9a98"},"source":["temp = test_df\n","test_df = test_sentences\n","test_sentences = test_df\n","test_df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence_id</th>\n","      <th>word_id</th>\n","      <th>word</th>\n","      <th>endword</th>\n","      <th>n_tokens</th>\n","      <th>cf_n_tokens</th>\n","      <th>n_chars</th>\n","      <th>n_char_lemmatized</th>\n","      <th>stopword</th>\n","      <th>number</th>\n","      <th>tags</th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>14</th>\n","      <th>15</th>\n","      <th>tf_idf</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>800</td>\n","      <td>0</td>\n","      <td>It's</td>\n","      <td>-1</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>PRP</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>800</td>\n","      <td>1</td>\n","      <td>the</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.181951</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>800</td>\n","      <td>2</td>\n","      <td>funniest</td>\n","      <td>-1</td>\n","      <td>3</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>JJ</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.413336</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>800</td>\n","      <td>3</td>\n","      <td>American</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>DT</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.327069</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>800</td>\n","      <td>4</td>\n","      <td>comedy</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NNS</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.341484</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>3549</th>\n","      <td>990</td>\n","      <td>5</td>\n","      <td>pursued</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>8</td>\n","      <td>7</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.380990</td>\n","    </tr>\n","    <tr>\n","      <th>3550</th>\n","      <td>990</td>\n","      <td>6</td>\n","      <td>a</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>9</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>DT</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.800000</td>\n","    </tr>\n","    <tr>\n","      <th>3551</th>\n","      <td>990</td>\n","      <td>7</td>\n","      <td>career</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>10</td>\n","      <td>6</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>VB</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.322910</td>\n","    </tr>\n","    <tr>\n","      <th>3552</th>\n","      <td>990</td>\n","      <td>8</td>\n","      <td>in</td>\n","      <td>-1</td>\n","      <td>1</td>\n","      <td>11</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>-1</td>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.193790</td>\n","    </tr>\n","    <tr>\n","      <th>3553</th>\n","      <td>990</td>\n","      <td>9</td>\n","      <td>politics</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>12</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>-1</td>\n","      <td>-1</td>\n","      <td>NN</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>1.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.0</td>\n","      <td>0.344346</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>3554 rows × 28 columns</p>\n","</div>"],"text/plain":["      sentence_id  word_id      word  endword  ...   13   14   15    tf_idf\n","0             800        0      It's       -1  ...  0.0  0.0  0.0  0.000000\n","1             800        1       the       -1  ...  0.0  0.0  0.0  0.181951\n","2             800        2  funniest       -1  ...  0.0  0.0  0.0  0.413336\n","3             800        3  American       -1  ...  0.0  0.0  0.0  0.327069\n","4             800        4    comedy       -1  ...  0.0  0.0  0.0  0.341484\n","...           ...      ...       ...      ...  ...  ...  ...  ...       ...\n","3549          990        5   pursued       -1  ...  0.0  0.0  0.0  0.380990\n","3550          990        6         a       -1  ...  0.0  0.0  0.0  0.800000\n","3551          990        7    career       -1  ...  0.0  1.0  0.0  0.322910\n","3552          990        8        in       -1  ...  0.0  0.0  0.0  0.193790\n","3553          990        9  politics        1  ...  0.0  0.0  0.0  0.344346\n","\n","[3554 rows x 28 columns]"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"sexnXq4rpakH"},"source":["len(test_sentences)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q7z_rq5uWNOz"},"source":["del model"],"execution_count":null,"outputs":[]}]}